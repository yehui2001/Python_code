{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相关库导入\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "plt.rcParams['font.sans-serif']=['SimHei']  # 防止中文出现乱码\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 防止中文出现乱码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像导入\n",
    "#img = cv2.imread('Images/lena.jpeg',1)\n",
    "#img = cv2.imread('Images/son.jpg',1)\n",
    "#img = cv2.imread('Images/woman2.png',1)\n",
    "#img = cv2.imread('Images/cameraman.jpg',1)\n",
    "#img = cv2.imread('Images/girl6.jpg',1)\n",
    "#img = cv2.imread('Images/girl7.jpg',1)     # 终极素材\n",
    "img = cv2.imread('Images/mopi.jpeg')\n",
    "#img = cv2.imread('Images/scene.jpg',1)\n",
    "#img = cv2.imread('Images/building.jpg',1)\n",
    "imgInfo = img.shape\n",
    "height = imgInfo[0]\n",
    "width = imgInfo[1]\n",
    "cv2.imshow('src',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gray World 色彩均衡 效果一般\n",
    "def Gray_World(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    sumR = 0\n",
    "    sumG = 0\n",
    "    sumB = 0\n",
    "    max = 0\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            sumR = sumR + img[i,j,2]\n",
    "            sumG = sumG + img[i,j,1]\n",
    "            sumB = sumB + img[i,j,0]              \n",
    "    avgR = sumR/(height*width)\n",
    "    avgG = sumG/(height*width)\n",
    "    avgB = sumB/(height*width)\n",
    "    print(avgR,avgG,avgB)\n",
    "    avgGray = (avgR+avgG+avgB)/3\n",
    "    ar = avgGray/avgR\n",
    "    ag = avgGray/avgG\n",
    "    ab = avgGray/avgB\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            img[i,j,2] = int(img[i,j,2]*ar)         # 对于图像中每个像素img[i,j] 调整其R、G、B分量 new Ｒ　＝　old Ｒ ＊ ａｒ\n",
    "            img[i,j,1] = int(img[i,j,1]*ag)\n",
    "            img[i,j,0] = int(img[i,j,0]*ab)\n",
    "            if(img[i,j,2]>max):                     # max为RGB三个分量中的最大值\n",
    "                max = img[i,j,2]\n",
    "            if(img[i,j,1]>max):\n",
    "                max = img[i,j,1]\n",
    "            if(img[i,j,0]>max):\n",
    "                max = img[i,j,0]\n",
    "    factor = max/255                                 # 归一化处理\n",
    "    print(factor)\n",
    "    if(factor>1):\n",
    "        for i in range(0,height):\n",
    "            for j in range(0,width):\n",
    "                img[i,j,2] = int(img[i,j,2]/factor)\n",
    "                img[i,j,1] = int(img[i,j,1]/factor)\n",
    "                img[i,j,0] = int(img[i,j,0]/factor)\n",
    "    cv2.imshow('dst',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return img\n",
    "#Img1 = Gray_World(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 伽马校正"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于参考白的算法\n",
    "pixels = cv2.calcHist([img], [0], None, [256], [0, 256])            # 计算每个灰度级中所含像素数，返回的是一个（256,1）的数组\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  改进的YCrCb转换公式 垃圾不好用\n",
    "ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      # RGB->YCrCb  \n",
    "(Y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图\n",
    "B = img[:,:,0]                                     # 获取B通道\n",
    "G = img[:,:,1]\n",
    "R = img[:,:,2]\n",
    "for i in range(imgInfo[0]):\n",
    "    for j in range(imgInfo[1]):\n",
    "        if(Y[i,j]<200):\n",
    "            cr = int((B[i,j]-Y[i,j])*0.713)\n",
    "            cb = int((B[i,j]-Y[i,j])*0.564)\n",
    "        else:\n",
    "            print(R[i,j],Y[i,j])\n",
    "            cr = ((R[i,j]-Y[i,j])**2*0.713*((-5000/91)*(Y[i,j]-200)**(-2.0)+7))\n",
    "            print(\"cr=\"+str(cr))\n",
    "            cb = int(-1*(B[i,j]-Y[i,j])**2*0.564*(125*(Y[i,j]-200)**(-2.0)-3))\n",
    "            print(\"cb=\"+str(cb))\n",
    "img2 = (Y,cr,cb)\n",
    "img3 =  cv2.cvtColor(img,cv2.COLOR_YCrCb2BGR)\n",
    "cv2.imshow(\"IMG\",img3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性动态调整\n",
    "def Dynamic_adjust_liner(img,th1,th2):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    dst = img.copy()\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "                if(img[i,j]<th1):\n",
    "                    dst[i,j]= 0\n",
    "                elif(img[i,j]<th2):\n",
    "                    dst[i,j]= 255/(th2-th1)*(img[i,j]-th1)\n",
    "                elif(img[i,j]>=th2):\n",
    "                     dst[i,j] = 255\n",
    "    cv2.imshow('dst',dst)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return dst\n",
    "\n",
    "dst = Dynamic_adjust_liner(img,100,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 肤色检测 基于YCrCb颜色空间的CrCb分量筛选\n",
    "def YCrCb_CrCb(img):\n",
    "    ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  \n",
    "    (y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "    height = imgInfo[0]\n",
    "    width = imgInfo[1]\n",
    "    dst = img.copy()\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            if(cr[i,j]>135 and cr[i,j]<175 and cb[i,j]>77 and cb[i,j]<127):\n",
    "                dst[i,j] = (255,255,255)\n",
    "            else:\n",
    "                dst[i,j] = (0,0,0)\n",
    "                \n",
    "    cv2.imshow('dst',dst)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return dst\n",
    "\n",
    "YCrCb_CrCb(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 肤色检测 基于YCrCb颜色空间的Cr分量+Otsu法阈值分割算法\n",
    "def YCrCb_OTSU(img):\n",
    "    start = time.time()\n",
    "    ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  \n",
    "    (y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "\n",
    "    # 高斯滤波, cr 是待滤波的源图像数据, (5,5)是值窗口大小, 0 是指根据窗口大小来计算高斯函数标准差\n",
    "    cr1 = cv2.GaussianBlur(cr, (5, 5), 0) # 对cr通道分量进行高斯滤波\n",
    "    # 根据OTSU算法求图像阈值, 对图像进行二值化\n",
    "    th, skin = cv2.threshold(cr1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) \n",
    "    end = time.time()\n",
    "    print(\"阈值为\"+str(th))\n",
    "    print(\"耗时\"+str(end-start)+\"秒\")\n",
    "    cv2.imshow(\"image CR\", cr1)\n",
    "    cv2.imshow(\"Skin Cr+OSTU\", skin )\n",
    "    cv2.waitKey(0)\n",
    "    return skin\n",
    "\n",
    "\n",
    "YCrCb_OTSU(Img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制YCrCb颜色空间图像\n",
    "ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  \n",
    "(y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10,10))          # 创建1X4的网格，其中每个子图大小为7X7 英寸：\n",
    "\n",
    "plt.subplot(1,4,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"原图\")                                       # 为第一个子图添加标题\n",
    "plt.xticks([])  #去掉横坐标值\n",
    "plt.yticks([])  #去掉纵坐标值\n",
    "plt.show\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(y,cmap='Greys_r')\n",
    "plt.title(\"y分量\")                                       \n",
    "plt.xticks([])  #去掉横坐标值\n",
    "plt.yticks([])  #去掉纵坐标值\n",
    "plt.show\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(cr,cmap='Greys_r')\n",
    "plt.title(\"Cr分量\")                                       \n",
    "plt.xticks([])  #去掉横坐标值\n",
    "plt.yticks([])  #去掉纵坐标值\n",
    "plt.show\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(cb,cmap='Greys_r')\n",
    "plt.title(\"Cb分量\")  \n",
    "plt.xticks([])  #去掉横坐标值\n",
    "plt.yticks([])  #去掉纵坐标值\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 像素分布概率直方图\n",
    "def showimg_pro_eachgray(img):                                          # 显示每一个灰度级的像素数概率\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                          # 灰度化处理\n",
    "          \n",
    "    pixels = cv2.calcHist([img], [0], None, [256], [0, 256])            # 计算每个灰度级中所含像素数，返回的是一个（256,1）的数组\n",
    "    p = pixels / (img.shape[0] * img.shape[1])                          # 获得每个灰度级中像素数占总像素数比例则我们获得了pi的一个向量\n",
    "    x = np.linspace(0, 255, 256)                                        # 横坐标灰度级别\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(img,'gray')                                              # 如果不加gray就会出现以前hsv与rgb的问题\n",
    "    plt.title('origin image')\n",
    "    plt.colorbar(orientation=\"horizontal\")                              # 水平放置颜色条\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.bar(x, p.ravel(), 0.9, alpha=1, color='b')\n",
    "    plt.title('Histogram of the probablity for each gray level',y=-0.4) # 调节标题上下移动的方法\n",
    "    plt.show()\n",
    "\n",
    "showimg_pro_eachgray(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手撸实现OTSU\n",
    "def OTSU(img):\n",
    "    #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                             # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    pixels = cv2.calcHist([img], [0], None, [256], [0, 256])                # 计算每个灰度级中所含像素数，返回的是一个（256,1）的数组\n",
    "    p = pixels / (img.shape[0] * img.shape[1])                              # 获得每个灰度级中像素数占总像素数比例则我们获得了p_i的一个向量\n",
    "    x=np.linspace(1,256,256)                                                # 灰度级像素范围定义，若定义为0～255，则求平均灰度级时会忽略第一个数据，所以我们定义为从1到256                                                 \n",
    "    maxvar=0\n",
    "    mG = np.sum(x*p)                                                        # 平均灰度级\n",
    "    th=0\n",
    "    step = 0\n",
    "    for k1 in range(1,256):                                                 # 暴力搜索\n",
    "        p1 = np.sum(p[0:k1])\n",
    "        p2 = np.sum(p[k1:256])\n",
    "        m1 = np.dot(x[0:k1],p[0:k1])/p1\n",
    "        m2 = np.dot(x[k1:256],p[k1:256])/p2\n",
    "        vars = p1*p2*(m1-m2)**2\n",
    "        if(vars>maxvar):\n",
    "            maxvar = vars\n",
    "            th = k1\n",
    "            step = step+1\n",
    "            print(\"第\"+str(step)+\"次找到最佳阈值\"+str(th)+\",\"+\"最大类间方差为\"+str(maxvar))\n",
    "    return th,maxvar \n",
    "print(\"最佳阈值是\"+str(OTSU(img)[0]),\"最大方差为\"+str(OTSU(img)[1]))\n",
    "\n",
    "\n",
    "# 基于手撸的OTSU 实现的YCrCb分割                  # 凸显改进算法的优越性，使用mopi.jpeg例子，能良好体现出改进之后的算法，具有更强的识别效果，在处理肤色相近，像素值集中的图像时更占上风\n",
    "def YCrCb_OTSU(img):\n",
    "    start  = time.time()                               # 引入计时模块\n",
    "    ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  有没有转换公式呢？\n",
    "    (y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "    cr1 = cv2.GaussianBlur(cr, (5, 5), 0) # # 高斯滤波, cr 是待滤波的源图像数据, (5,5)是值窗口大小, 0 是指根据窗口大小来计算高斯函数标准差\n",
    "    th = OTSU(cr1)[0]\n",
    "    skin = cr1.copy()\n",
    "    # 根据OTSU算法求图像阈值, 对图像进行二值化 获得人脸部分（白色）,会发现因为手部与脸部肤色相近，故被认定为前景（人脸部分）\n",
    "    for i in range(0,img.shape[0]):\n",
    "        for j in range(0,img.shape[1]):\n",
    "            if(cr1[i,j]< th):           \n",
    "                skin[i,j]= 0  \n",
    "            else:  \n",
    "                skin[i,j] = 255\n",
    "\n",
    "    # # 原图的人脸部分\n",
    "    # for i in range(0,img.shape[ßß0]):\n",
    "    #     for j in range(0,img.shape[1]): \n",
    "    #         if(skin[i,j]==0):\n",
    "    #             img[i,j] = 0\n",
    "    # cv2.imshow(\"SKin\",img)\n",
    "    end = time.time()\n",
    "    print(\"耗时\"+str(end-start)+\"s\")\n",
    "    # 显示图像\n",
    "    cv2.imshow(\"Skin Cr+OSTU_Hand\", skin) # 因为通过对YCrCb空间分割再还原RGB比较麻烦\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "#YCrCb_OTSU(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTSU法实现图像分割\n",
    "def OTSU_Seg(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                             # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    _, obj = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # cv2.imshow(\"img\",img)\n",
    "    # cv2.imshow(\"Use_OTSU_Seg\",obj)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return obj\n",
    "\n",
    "obj = OTSU_Seg(img)  \n",
    "#figure()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,14))          # 创建1X2的网格，其中每个子图大小为14X14 英寸：\n",
    "plt.subplot(1,2,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"Lena.jpg\")                                       # 为第一个子图添加标题\n",
    "\n",
    "plt.subplot(1,2,2)                                      # 占据第二个位置\n",
    "plt.imshow(obj,cmap='Greys_r')                          # plt默认显示三通道图像\n",
    "plt.title(\"调用threshold函数+OTSU阈值分割后\")                              # 为第一个子图添加标题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手撸OTSU实现图像分割\n",
    "def OTSU_Seg_Hand(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                             # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    th = OTSU(img)[0]\n",
    "    for i in range(0,img.shape[0]):\n",
    "        for j in range(0,img.shape[1]):     \n",
    "            if(img[i,j]<th):\n",
    "                img[i,j]=0\n",
    "            else:\n",
    "                img[i,j]=255\n",
    "    return img \n",
    "obj = OTSU_Seg_Hand(img)  \n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,14))          # 创建1X2的网格，其中每个子图大小为14X14 英寸：\n",
    "plt.subplot(1,2,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"Cameraman.jpg\")                                       # 为第一个子图添加标题\n",
    "\n",
    "plt.subplot(1,2,2)                                      # 占据第二个位置\n",
    "plt.imshow(obj,cmap='Greys_r')                          # plt默认显示三通道图像\n",
    "plt.title(\"使用手撸OTSU法阈值分割后\")                              # 为第一个子图添加标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多阈值分割的OTSU改进算法    用于处理口红色号较深，将口红认定为前景的情况\n",
    "def OTSU_Mult_IMPROVE(img):\n",
    "    pixels = cv2.calcHist([img], [0], None, [256], [0, 256])                # 计算每个灰度级中所含像素数，返回的是一个（256,1）的数组\n",
    "    p = pixels / (img.shape[0] * img.shape[1])                              # 获得每个灰度级中像素数占总像素数比例则我们获得了p_i的一个向量\n",
    "    x=np.linspace(1,256,256)                                                # 灰度级像素范围定义，若定义为0～255，则求平均灰度级时会忽略第一个数据，所以我们定义为从1到256                                                 \n",
    "    sigma_b = 0                                                             # 类间方差\n",
    "    sigma_in = 0                                                            # 类内方差\n",
    "    maxvar = 0                                                              # 最大类间类内方差\n",
    "    mu_T = np.sum(x*p)                                                        # 平均灰度级\n",
    "    th1=0\n",
    "    th2=0\n",
    "    step = 0\n",
    "    for k1 in range(1,256):                                                 # 暴力搜索\n",
    "        for k2 in range(1,256):\n",
    "                a0 = np.sum(p[0:k1])\n",
    "                a1 = np.sum(p[k1:256])\n",
    "                a2 = 1-a0-a1\n",
    "                mu_0 = np.dot(x[0:k1],p[0:k1])/a0\n",
    "                mu_1 = np.dot(x[k1:k2],p[k1:k2])/a1\n",
    "                mu_2 = np.dot(x[k2:256],p[k2:256])/a2\n",
    "                vars1 = a0*(mu_0-mu_T)**2+a1*(mu_1-mu_T)**2+a2*(mu_2-mu_T)**2\n",
    "\n",
    "    return th1,th2,maxvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于手撸的OTSU_IMPROVE 实现的YCrCb分割                  \n",
    "# 凸显改进算法的优越性，使用mopi.jpeg例子，能良好体现出改进之后的算法，具有更强的识别效果，在处理肤色相近，像素值集中的图像时更占上风\n",
    "\n",
    "#  手撸实现最大类间类内方差比 \n",
    "def OTSU_IMPROVE(img):\n",
    "    #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                          # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    pixels = cv2.calcHist([img], [0], None, [256], [0, 256])                # 计算每个灰度级中所含像素数，返回的是一个（256,1）的数组\n",
    "    p = pixels / (img.shape[0] * img.shape[1])                              # 获得每个灰度级中像素数占总像素数比例则我们获得了p_i的一个向量\n",
    "    x=np.linspace(1,256,256)                                                # 灰度级像素范围定义，若定义为0～255，则求平均灰度级时会忽略第一个数据，所以我们定义为从1到256                                                 \n",
    "    sigma_b = 0                                                             # 类间方差\n",
    "    sigma_in = 0                                                            # 类内方差\n",
    "    maxvar = 0                                                              # 最大类间类内方差比\n",
    "    mG = np.sum(x*p)                                                        # 平均灰度级\n",
    "    th=0\n",
    "    step = 0\n",
    "    for k1 in range(1,256):                                                 # 暴力搜索\n",
    "        p1 = np.sum(p[0:k1])\n",
    "        p2 = np.sum(p[k1:256])\n",
    "        m1 = np.dot(x[0:k1],p[0:k1])/p1\n",
    "        m2 = np.dot(x[k1:256],p[k1:256])/p2\n",
    "        vars1 = p1*p2*(m1-m2)**2\n",
    "        if(vars1>sigma_b):\n",
    "            sigma_b = vars1\n",
    "        vars2 = np.sum(p[0:k1]*(x[0:k1]-m1)**2)+np.sum(p[k1:256]*(x[k1:256]-m2)**2)\n",
    "        if(vars2>sigma_in):\n",
    "            sigma_in = vars2\n",
    "        if(sigma_in>0):\n",
    "            vars = sigma_b/sigma_in\n",
    "        else:\n",
    "            vars = 0\n",
    "        if(vars>maxvar):\n",
    "            maxvar = vars\n",
    "            th = k1\n",
    "            step = step + 1\n",
    "            print(\"第\"+str(step)+\"次找到最佳阈值\"+str(th)+\",\"+\"最大类间方差为\"+str(maxvar))\n",
    "    return th,maxvar \n",
    "\n",
    "print(\"最佳阈值是\"+str(OTSU_IMPROVE(img)[0]),\"最大方差比为\"+str(OTSU_IMPROVE(img)[1]))    \n",
    "\n",
    "        \n",
    "def YCrCb_OTSU_IMPROVE(img):\n",
    "    start  = time.time()                               # 引入计时模块\n",
    "    ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  有没有转换公式呢？\n",
    "    (y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "    cr1 = cv2.GaussianBlur(cr, (5, 5), 0) # # 高斯滤波, cr 是待滤波的源图像数据, (5,5)是值窗口大小, 0 是指根据窗口大小来计算高斯函数标准差\n",
    "    th = OTSU_IMPROVE(cr1)[0]\n",
    "    skin = cr1.copy()\n",
    "    # 根据OTSU算法求图像阈值, 对图像进行二值化 获得人脸部分（白色）,会发现因为手部与脸部肤色相近，故被认定为前景（人脸部分）\n",
    "    for i in range(0,img.shape[0]):\n",
    "        for j in range(0,img.shape[1]):\n",
    "            if(cr1[i,j]< th):           \n",
    "                skin[i,j]= 0  \n",
    "            else:  \n",
    "                skin[i,j] = 255\n",
    "\n",
    "    # # 原图的人脸部分\n",
    "    # for i in range(0,img.shape[ßß0]):\n",
    "    #     for j in range(0,img.shape[1]): \n",
    "    #         if(skin[i,j]==0):\n",
    "    #             img[i,j] = 0\n",
    "    # cv2.imshow(\"SKin\",img)\n",
    "    end = time.time()\n",
    "    print(\"耗时\"+str(end-start)+\"s\")\n",
    "    #显示图像\n",
    "    cv2.imshow(\"Skin Cr+OSTU_IMPROVE_Hand\", skin) # 因为通过对YCrCb空间分割再还原RGB比较麻烦\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return skin\n",
    "\n",
    "YCrCb_OTSU_IMPROVE(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YCrCb_OTSU及其改进算法的作图\n",
    "skin1 = YCrCb_OTSU(img)\n",
    "skin2=  YCrCb_OTSU_IMPROVE(img)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14,14))          # 创建1X2的网格，其中每个子图大小为14X14 英寸：\n",
    "plt.subplot(1,3,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"原图\")                                       # 为第一个子图添加标题\n",
    "\n",
    "plt.subplot(1,3,2)                                      # 占据第二个位置\n",
    "plt.imshow(skin1,cmap='Greys_r')                         \n",
    "plt.title(\"使用手撸OTSU法阈值分割后\")                          \n",
    "\n",
    "plt.subplot(1,3,3)                                      # 占据第三个位置\n",
    "plt.imshow(skin2,cmap='Greys_r')                        \n",
    "plt.title(\"使用YCrCb+改进OTSU法阈值分割后\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手撸OTSU_IMPROVE实现图像分割\n",
    "def OTSU_Seg_IMPROVE(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                             # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    th = OTSU_IMPROVE(img)[0]\n",
    "    for i in range(0,img.shape[0]):\n",
    "        for j in range(0,img.shape[1]):     \n",
    "            if(img[i,j]<th):\n",
    "                img[i,j]=0\n",
    "            else:\n",
    "                img[i,j]=255\n",
    "    return img \n",
    "obj = OTSU_Seg_IMPROVE(img)  \n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,14))          # 创建1X2的网格，其中每个子图大小为14X14 英寸：\n",
    "plt.subplot(1,2,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"Cameraman.jpg\")                                       # 为第一个子图添加标题\n",
    "\n",
    "plt.subplot(1,2,2)                                      # 占据第二个位置\n",
    "plt.imshow(obj,cmap='Greys_r')                          # plt默认显示三通道图像\n",
    "plt.title(\"使用改进的OTSU法阈值分割后\")                              # 为第一个子图添加标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二次多项式模式检测\n",
    "def Quad_poly(img):\n",
    "    Info = img.shape\n",
    "    height = Info[0]\n",
    "    width = Info[1]\n",
    "    Channels = Info[2]\n",
    "    # 创建一个与原图像大小相同的零数组\n",
    "    skin = np.zeros((height,width),np.uint8)\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            B = img[i,j,0]\n",
    "            G = img[i,j,1]\n",
    "            R = img[i,j,2]\n",
    "            if(R-G>=20):\n",
    "                if(G>B):\n",
    "                    sum = R+G+B\n",
    "                    t1 = 100*R-33*sum\n",
    "                    t2 = 100*G-33*sum\n",
    "                    if((t1**2+t2**2)>=4*sum*sum):\n",
    "                        T1 = 10000*G*sum\n",
    "                        lower = -7760*R**2 + 5601*R*sum + 1766*sum**2\n",
    "                        if(T1>lower):\n",
    "                            upper = -13767*R**2 + 10743*R*sum + 1452*sum**2\n",
    "                            if(T1<upper):\n",
    "                                skin[i,j] = 255\n",
    "    cv2.imshow('skin2',skin)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return skin\n",
    "#skin = Quad_poly(img)\n",
    "# 效果垃圾 笑果还行     人脸面部会反光，导致反光区域的RGB值偏高，会被筛选出人脸区域，而人脸轮廓例如脸颊、腮部亮度比较稳定，会被识别为人脸区域\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于HSV颜色空间H，S，V范围筛选法\n",
    "def HSV(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # 把图像转换到HSV色域\n",
    "    (h, s, v) = cv2.split(hsv) # 图像分割, 分别获取h, s, v 通道分量图像\n",
    "    skin = np.zeros(h.shape, np.uint8)  # 根据源图像的大小创建一个全0的矩阵,用于保存图像数据\n",
    "    (height, width) = img.shape[0:2] # 获取源图像数据的长和宽\n",
    "\n",
    "    # 遍历图像, 判断HSV通道的数值, 如果在指定范围中, 则置把新图像的点设为255,否则设为0\n",
    "    for i in  range(0, height):\n",
    "        for j in  range(0, width):\n",
    "            if (h[i][j] >  2) and (h[i][j] <  15) and (s[i][j] >  35) and (s[i][j] <  255) and (v[i][j] >  60) and (v[i][j] <  255):\n",
    "                skin[i][j] =  255\n",
    "            else:\n",
    "                skin[i][j] =  0\n",
    "    cv2.imshow('skin',skin)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return skin\n",
    "\n",
    "# hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # 把图像转换到HSV色域\n",
    "# cv2.imshow('hsv',hsv)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "#HSV(img)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 双边滤波\n",
    "dst1 = cv2.bilateralFilter(img,15,35,35) # 邻域半径为15 sigma_d为空间高斯函数标准差，sigma_r为灰度值相似性高斯函数标准差\n",
    "#cv2.imshow('dst1',dst1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 磨皮算法 \n",
    "# 通过上述算法获得皮肤区域，遍历双边滤波后的矩阵，将非皮肤区域还原\n",
    "def skin_(dst1,img,skin1):       #dst1 为双边滤波后的矩阵  img 为原图 skin1 为皮肤区域\n",
    "    dst2 = dst1.copy()\n",
    "    for i in range(0,height):   \n",
    "        for j in range(0,width):\n",
    "            if(skin1[i,j] == 0):\n",
    "                dst2[i,j] = img[i,j]\n",
    "\n",
    "    cv2.imshow('dst2',dst2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
