{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 相关库导入\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "plt.rcParams['font.sans-serif']=['SimHei']  # 防止中文出现乱码\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 防止中文出现乱码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 图像导入\n",
    "#img = cv2.imread('Images/lena.jpeg',1)\n",
    "#img = cv2.imread('Images/girl.jpeg',1)\n",
    "#img = cv2.imread('Images/woman2.png',1)\n",
    "#img = cv2.imread('Images/cameraman.jpg',1)\n",
    "#img = cv2.imread('Images/girl6.jpg',1)\n",
    "#img = cv2.imread('Images/girl7.jpg',1)     # 终极素材\n",
    "img = cv2.imread('Images/mopi.jpeg')\n",
    "#img = cv2.imread('Images/QUT2.jpg',1)\n",
    "#img = cv2.imread('Images/building.jpg',1)\n",
    "imgInfo = img.shape\n",
    "height = imgInfo[0]\n",
    "width = imgInfo[1]\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Image', 1600, 900)\n",
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gray World 色彩均衡 效果一般\n",
    "def Gray_World(img):\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    sumR = 0\n",
    "    sumG = 0\n",
    "    sumB = 0\n",
    "    max = 0\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            sumR = sumR + img[i,j,2]\n",
    "            sumG = sumG + img[i,j,1]\n",
    "            sumB = sumB + img[i,j,0]              \n",
    "    avgR = sumR/(height*width)\n",
    "    avgG = sumG/(height*width)\n",
    "    avgB = sumB/(height*width)\n",
    "    print(avgR,avgG,avgB)\n",
    "    avgGray = (avgR+avgG+avgB)/3\n",
    "    ar = avgGray/avgR\n",
    "    ag = avgGray/avgG\n",
    "    ab = avgGray/avgB\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            img[i,j,2] = int(img[i,j,2]*ar)         # 对于图像中每个像素img[i,j] 调整其R、G、B分量 new Ｒ　＝　old Ｒ ＊ ａｒ\n",
    "            img[i,j,1] = int(img[i,j,1]*ag)\n",
    "            img[i,j,0] = int(img[i,j,0]*ab)\n",
    "            if(img[i,j,2]>max):                     # max为RGB三个分量中的最大值\n",
    "                max = img[i,j,2]\n",
    "            if(img[i,j,1]>max):\n",
    "                max = img[i,j,1]\n",
    "            if(img[i,j,0]>max):\n",
    "                max = img[i,j,0]\n",
    "    factor = max/255                                 # 归一化处理\n",
    "    print(factor)\n",
    "    if(factor>1):\n",
    "        for i in range(0,height):\n",
    "            for j in range(0,width):\n",
    "                img[i,j,2] = int(img[i,j,2]/factor)\n",
    "                img[i,j,1] = int(img[i,j,1]/factor)\n",
    "                img[i,j,0] = int(img[i,j,0]/factor)\n",
    "    cv2.imshow('dst',img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return img\n",
    "#Img1 = Gray_World(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 伽马校正\n",
    "def Gamma_correction(img,gamma):\n",
    "    dst = np.array(255 * (img / 255) ** gamma, dtype='uint8')           # 先归一化处理， 再进行非线性变换，最后再映射到[0,255]\n",
    "    cv2.imshow('src',img)\n",
    "    cv2.imshow('dst',dst)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "Gamma_correction(img,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直方图均衡化 适用于灰度图像\n",
    "#def Hist_equalization_Grey(img):\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "equ = cv2.equalizeHist(gray)\n",
    "cv2.imshow('src',img)\n",
    "cv2.imshow('equ',equ)\n",
    "\n",
    "plt.hist(img.ravel(),256,[0,256],label='原图')\n",
    "plt.figure\n",
    "plt.hist(equ.ravel(),256,[0,256],label = '均衡化后')\n",
    "plt.xlabel('灰度值')\n",
    "plt.ylabel('频数')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#Hist_equalization_Grey(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 局部直方图均衡化\n",
    "# 思路： 将原图分成若干个小块，对每个小块进行直方图均衡化，然后将均衡化后的图像合并起来\n",
    "# 这种方法主要对于图像直方图不是那么单一的（比如存在多峰情况）图像比较实用\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "clahe = cv2.createCLAHE(clipLimit=2, tileGridSize=(300,300))\n",
    "result = clahe.apply(gray)\n",
    "\n",
    "#显示图像\n",
    "plt.subplot(221)\n",
    "plt.imshow(gray, cmap=plt.cm.gray), plt.axis(\"off\"), plt.title('（a）') \n",
    "plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.4, hspace=0.3)       # wspace调整子图的间距\n",
    "plt.subplot(222)\n",
    "plt.imshow(equ, cmap=plt.cm.gray), plt.axis(\"off\"), plt.title('（b）') \n",
    "plt.subplot(223)\n",
    "plt.hist(img.ravel(), 256)\n",
    "plt.title('（c）') \n",
    "plt.xlabel('灰度值')\n",
    "plt.ylabel('频数')\n",
    "plt.subplot(224)\n",
    "plt.hist(equ.ravel(), 256,color='#ff7f0e')\n",
    "plt.title('（d）')\n",
    "plt.xlabel('灰度值')\n",
    "plt.ylabel('频数')\n",
    "plt.show()\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直方图均衡化对比\n",
    "equ = cv2.equalizeHist(gray)\n",
    "plt.hist(equ.ravel(),256,[0,256],label=\"直方图均衡化\")\n",
    "plt.hist(result.ravel(), 256,label=\"局部直方图均衡化\")\n",
    "plt.xlabel('灰度值')\n",
    "plt.ylabel('频数')\n",
    "plt.legend(loc='upper right')       # 添加图例\n",
    "#plt.title(\"直方图均衡化对比\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 直方图均衡化 适用于彩色图像 \n",
    "# 思路1：步骤分别对BGR三个通道进行直方图均衡化，然后合并即可\n",
    "# 思路2：将其分离成HSI空间，其中I是亮度，单独对亮度进行均衡化即可\n",
    "#图形美化设置\n",
    "\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "# 科学计数法形式函数\n",
    "def formatnum(x, pos):\n",
    "    return '%.2f×10$^{5}$' % (x/1e5)\n",
    "\n",
    "def Hist_equalization_RGB(img):\n",
    "    R = img[:,:,2]\n",
    "    G = img[:,:,1]\n",
    "    B = img[:,:,0]\n",
    "    R_equ = cv2.equalizeHist(R)                 # 均衡化\n",
    "    G_equ = cv2.equalizeHist(G)         \n",
    "    B_equ = cv2.equalizeHist(B)\n",
    "    img_equ = cv2.merge([B_equ,G_equ,R_equ])    # 合并　\n",
    "    # 显示图像\n",
    "    plt.figure(0)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"原图像\")\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(img_equ)\n",
    "    plt.title(\"对RGB色彩均衡化处理后\")\n",
    "\n",
    "    # cv2.namedWindow('src', cv2.WINDOW_NORMAL)\n",
    "    # cv2.resizeWindow('src', 1600, 900)\n",
    "    # cv2.imshow('src',img)\n",
    "    # cv2.namedWindow('equ', cv2.WINDOW_NORMAL)\n",
    "    # cv2.resizeWindow('equ', 1600, 900)\n",
    "    # cv2.imshow('equ',img_equ)                   \n",
    "\n",
    "    # 以下为直方图绘制代码\n",
    "    plt.figure(1)\n",
    "\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.xlim(0,256)                             # 限制x坐标轴的范围\n",
    "    plt.hist(R.ravel(),256,[0,256],label='原R分量灰度直方图',color='red')\n",
    "    plt.xlabel('灰度值')\n",
    "    plt.ylabel('频数')\n",
    "    formatter = FuncFormatter(formatnum)\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.legend(loc='upper right')       # 添加图例\n",
    "    # ax = plt.gca()        # 1e3 形式\n",
    "    # ax.ticklabel_format(style='sci', scilimits=(-1,2), axis='y')\n",
    "    # ax.get_yaxis().get_offset_text().set(va='bottom', ha='left')\n",
    "    # ax.yaxis.get_offset_text().set_fontsize(16)#设置1e6的大小与位置\n",
    "\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.hist(R_equ.ravel(),256,[0,256],label='均衡化后直方图',color='OrangeRed')\n",
    "    plt.xlim(0,256)                             # 限制x坐标轴的范围\n",
    "    plt.subplots_adjust(left=0.1, right=0.9, bottom=0.1, top=0.9, wspace=0.5, hspace=0.3)       # wspace调整子图的间距\n",
    "    formatter = FuncFormatter(formatnum)\n",
    "    plt.gca().yaxis.set_major_formatter(formatter)\n",
    "    plt.xlabel('灰度值')\n",
    "    plt.ylabel('频数')\n",
    "    plt.legend(loc='upper right')       # 添加图例\n",
    "    #plt.yticks(np.linspace(0,4e3,5),fontsize=10)\n",
    "    #plt.suptitle(\"R分量直方图均衡化结果图\")\n",
    "    plt.show()\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "Hist_equalization_RGB(img)\n",
    "\n",
    "def Hist_equalization_HSI(img):\n",
    "    HSI_img = cv2. cvtColor(img,cv2.COLOR_BGR2HSV_FULL)\n",
    "\n",
    "    H = HSI_img[:,:,0]\n",
    "    S = HSI_img[:,:,1]\n",
    "    I = HSI_img[:,:,2]\n",
    "    I_equ = cv2.equalizeHist(I)\n",
    "    equ = cv2.merge([H,S,I_equ])\n",
    "    cv2.namedWindow('src', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('src', 1600, 900)\n",
    "    cv2.imshow('src',img)\n",
    "    cv2.namedWindow('equ', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('equ', 1600, 900)\n",
    "    cv2.imshow('equ',cv2.cvtColor(equ,cv2.COLOR_HSV2BGR))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "#Hist_equalization_HSI(img)\n",
    "\n",
    "\n",
    "def Hist_equalization_HSV(img):\n",
    "    HSI_img = cv2. cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    H = HSI_img[:,:,0]\n",
    "    S = HSI_img[:,:,1]\n",
    "    V = HSI_img[:,:,2]\n",
    "    V_equ = cv2.equalizeHist(V)\n",
    "    equ = cv2.merge([H,S,V_equ])\n",
    "    cv2.namedWindow('src', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('src', 1600, 900)\n",
    "    cv2.imshow('src',img)\n",
    "    cv2.namedWindow('equ', cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('equ', 1600, 900)\n",
    "    cv2.imshow('equ',cv2.cvtColor(equ,cv2.COLOR_HSV2BGR))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "#Hist_equalization_HSV(img)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 61,  65, 113],\n",
       "        [ 56,  60, 108],\n",
       "        [ 53,  57, 105],\n",
       "        ...,\n",
       "        [108, 140, 207],\n",
       "        [110, 142, 209],\n",
       "        [104, 136, 203]],\n",
       "\n",
       "       [[ 59,  63, 111],\n",
       "        [ 54,  58, 106],\n",
       "        [ 53,  57, 105],\n",
       "        ...,\n",
       "        [112, 144, 211],\n",
       "        [112, 144, 211],\n",
       "        [112, 144, 211]],\n",
       "\n",
       "       [[ 59,  63, 111],\n",
       "        [ 54,  58, 106],\n",
       "        [ 53,  57, 105],\n",
       "        ...,\n",
       "        [113, 145, 212],\n",
       "        [111, 143, 210],\n",
       "        [116, 148, 215]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 38,  43,  96],\n",
       "        [ 38,  43,  96],\n",
       "        [ 38,  43,  96],\n",
       "        ...,\n",
       "        [214, 166, 162],\n",
       "        [214, 166, 162],\n",
       "        [214, 166, 162]],\n",
       "\n",
       "       [[ 38,  43,  96],\n",
       "        [ 38,  43,  96],\n",
       "        [ 38,  43,  96],\n",
       "        ...,\n",
       "        [214, 166, 162],\n",
       "        [214, 166, 162],\n",
       "        [215, 167, 163]],\n",
       "\n",
       "       [[ 38,  43,  96],\n",
       "        [ 38,  43,  96],\n",
       "        [ 38,  43,  96],\n",
       "        ...,\n",
       "        [214, 166, 162],\n",
       "        [215, 167, 163],\n",
       "        [215, 167, 163]]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 通过直方图均衡化对Cr分量进行处理\n",
    "def Hist_equalization_Cr(img):\n",
    "    ycbcr = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "    Cr = ycbcr[:,:,1]\n",
    "    #Cr_equ = cv2.equalizeHist(Cr)\n",
    "    clahe = cv2.createCLAHE(clipLimit=0.6, tileGridSize=(30,30))\n",
    "    y_equ = ycbcr[:,:,0]\n",
    "    Cr_equ = clahe.apply(Cr)\n",
    "    cv2.imshow(\"1\",Cr)\n",
    "    cv2.imshow(\"2\",Cr_equ)\n",
    "    ycbcr_equ = cv2.merge([y_equ,Cr_equ,ycbcr[:,:,2]])\n",
    "    img_equ = cv2.cvtColor(ycbcr_equ, cv2.COLOR_YCR_CB2BGR)\n",
    "    cv2.imshow(\"img\",img)\n",
    "    cv2.imshow(\"equ\",img_equ)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return img_equ\n",
    "\n",
    "Hist_equalization_Cr(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 腐蚀 膨胀\n",
    "def erode(img,kernel):\n",
    "    height, width = img.shape\n",
    "    h = kernel.shape[0]\n",
    "    w = kernel.shape[1]\n",
    "    erosion = np.zeros((height,width),np.uint8)\n",
    "    _,Result = cv2.threshold(img,66,1,cv2.THRESH_BINARY)                        # 将图像中的像素映射到0和1 主要调第二个参数值\n",
    "    for i in range(h//2,height-h//2):                                           # // 代表向下取整整除\n",
    "        for j in range(h//2,width-h//2):\n",
    "            if np.sum(Result[i-h//2:i+h//2+1,j-h//2:j+h//2+1]*kernel)< 9:       # *为普通的点乘 与运算\n",
    "                erosion[i,j] = 0                                                # 前景为白色,若该位置像素点不存在，则另其为0（黑色，背景色）\n",
    "            else:\n",
    "                erosion[i,j] = np.max(img[i-h//2:i+h//2+1,j-h//2:j+h//2+1])     # 取模板覆盖中的最大值\n",
    "    return erosion\n",
    "\n",
    "def dilate(img,kernel):\n",
    "    height, width = img.shape\n",
    "    h = kernel.shape[0]\n",
    "    w = kernel.shape[1]\n",
    "    dilation = np.zeros((height,width),np.uint8)\n",
    "    _,Result = cv2.threshold(img,30,1,cv2.THRESH_BINARY)                        # 将图像中的像素映射到0和1 主要调第二个参数值\n",
    "    for i in range(h//2,height-h//2):                                           # // 代表向下取整整除\n",
    "        for j in range(h//2,width-h//2):\n",
    "            if np.sum(Result[i-h//2:i+h//2+1,j-h//2:j+h//2+1]*kernel)< 1:       # *为普通的点乘 与运算\n",
    "                dilation[i,j] = 0                                               # 前景为白色\n",
    "            else:\n",
    "                dilation[i,j] = np.max(img[i-h//2:i+h//2+1,j-h//2:j+h//2+1])\n",
    "    return dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def reference_white(img):\n",
    "#     img_b = np.sort(img[:, :, 0].reshape( -1))\n",
    "#     img_g = np.sort(img[:, :, 1].reshape( -1))\n",
    "#     img_r = np.sort(img[:, :, 2].reshape( -1))\n",
    "#     num1 = int(img_b.shape[0] * 0.05)\n",
    "#     num2 = int(img_g.shape[0] * 0.05)\n",
    "#     num3 = int(img_r.shape[0] * 0.05)\n",
    "#     img_b_mean = np.mean(img_b[-num1:])\n",
    "#     img_g_mean = np.mean(img_g[-num2:])\n",
    "#     img_r_mean = np.mean(img_r[-num3:])\n",
    "#     img[:, :, 0] = np.uint8(np.minimum(img[:, :, 0] * (255 / img_b_mean), 255))\n",
    "#     img[:, :, 1] = np.uint8(np.minimum(img[:, :, 1] * (255 / img_g_mean), 255))\n",
    "#     img[:, :, 2] = np.uint8(np.minimum(img[:, :, 2] * (255 / img_r_mean), 255))\n",
    "#     return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考白算法 知乎找的，没找到源文献\n",
    "def reference_white(img):\n",
    "    img_shape = img.shape\n",
    "    img_b = img[:,:,0].astype('float')\n",
    "    img_g = img[:,:,1].astype('float')\n",
    "    img_r = img[:,:,2].astype('float')\n",
    "    \n",
    "    img_ycbcr = cv2.cvtColor(img, cv2.COLOR_BGR2YCR_CB)\n",
    "    img_y = img_ycbcr[:,:,0]\n",
    "    img_y_sort = np.sort(img_y.reshape( -1))\n",
    "    num = int(img_y_sort.shape[0] * 0.03)\n",
    "    T1 = img_y_sort[-num]\n",
    "    T2 = img_y_sort[num]\n",
    "    \n",
    "    n1 = 0\n",
    "    n2 = 0\n",
    "    img_r_big_sum = 0\n",
    "    img_g_big_sum = 0\n",
    "    img_b_big_sum = 0\n",
    "    img_r_small_sum = 0\n",
    "    img_g_small_sum = 0\n",
    "    img_b_small_sum = 0\n",
    "    \n",
    "    for i in range(img_shape[0]):\n",
    "        for j in range(img_shape[1]):\n",
    "            if img_y[i, j] >= T1:\n",
    "                img_r_big_sum =+ img_r[i,j]\n",
    "                img_g_big_sum =+ img_g[i,j]\n",
    "                img_b_big_sum =+ img_b[i,j]\n",
    "                n1 =+ 1\n",
    "\n",
    "            if img_y[i, j] <= T2:\n",
    "                img_r_small_sum = + img_r[i, j]\n",
    "                img_g_small_sum = + img_g[i, j]\n",
    "                img_b_small_sum = + img_b[i, j]\n",
    "                n2 =+ 1\n",
    "    \n",
    "    r_mean1 = img_r_big_sum/n1\n",
    "    g_mean1 = img_g_big_sum/n1\n",
    "    b_mean1 = img_b_big_sum/n1\n",
    "    \n",
    "    r_mean2 = img_r_small_sum/n2\n",
    "    g_mean2 = img_g_small_sum/n2\n",
    "    b_mean2 = img_b_small_sum/n2\n",
    "\n",
    "    gama_r = -1\n",
    "    gama_g = -1\n",
    "    gama_b = -1\n",
    "    \n",
    "    print(r_mean2, r_mean1)\n",
    "    for i in range(img_shape[0]):\n",
    "        for j in range(img_shape[1]):\n",
    "            img_r[i,j] = (img_r[i,j] - r_mean2)/(r_mean2 - r_mean1)*gama_r\n",
    "            img_g[i,j] = (img_g[i,j] - g_mean2)/(g_mean2 - g_mean1)*gama_g\n",
    "            img_b[i,j] = (img_b[i,j] - b_mean2)/(b_mean2 - b_mean1)*gama_b\n",
    "            \n",
    "    img_new = np.zeros(shape=[img_shape[0], img_shape[1], 3])\n",
    "    img_new[:,:,0] = img_b\n",
    "    img_new[:,:,1] = img_g\n",
    "    img_new[:,:,2] = img_r\n",
    "\n",
    "    img_new = np.minimum(img_new, 1)\n",
    "    img_new = np.maximum(img_new,0)\n",
    "    img_new = np.uint8(img_new*255)\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.imshow('img_new',img_new)\n",
    "    cv2.waitKey()\n",
    "    return img_new\n",
    "\n",
    "reference_white(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  改进的YCrCb转换公式 垃圾不好用\n",
    "ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      # RGB->YCrCb  \n",
    "(Y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图\n",
    "B = img[:,:,0]                                     # 获取B通道\n",
    "G = img[:,:,1]\n",
    "R = img[:,:,2]\n",
    "for i in range(imgInfo[0]):\n",
    "    for j in range(imgInfo[1]):\n",
    "        if(Y[i,j]<200):\n",
    "            cr = int((B[i,j]-Y[i,j])*0.713)\n",
    "            cb = int((B[i,j]-Y[i,j])*0.564)\n",
    "        else:\n",
    "            print(R[i,j],Y[i,j])\n",
    "            cr = ((R[i,j]-Y[i,j])**2*0.713*((-5000/91)*(Y[i,j]-200)**(-2.0)+7))\n",
    "            print(\"cr=\"+str(cr))\n",
    "            cb = int(-1*(B[i,j]-Y[i,j])**2*0.564*(125*(Y[i,j]-200)**(-2.0)-3))\n",
    "            print(\"cb=\"+str(cb))\n",
    "img2 = (Y,cr,cb)\n",
    "img3 =  cv2.cvtColor(img,cv2.COLOR_YCrCb2BGR)\n",
    "cv2.imshow(\"IMG\",img3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线性动态调整\n",
    "def Dynamic_adjust_liner(img,th1,th2):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    dst = img.copy()\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "                if(img[i,j]<th1):\n",
    "                    dst[i,j]= 0\n",
    "                elif(img[i,j]<th2):\n",
    "                    dst[i,j]= 255/(th2-th1)*(img[i,j]-th1)\n",
    "                elif(img[i,j]>=th2):\n",
    "                     dst[i,j] = 255\n",
    "    cv2.imshow('dst',dst)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return dst\n",
    "\n",
    "dst = Dynamic_adjust_liner(img,100,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 肤色检测 基于YCrCb颜色空间的CrCb分量筛选\n",
    "def YCrCb_CrCb(img):\n",
    "    ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  \n",
    "    (y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "    height = imgInfo[0]\n",
    "    width = imgInfo[1]\n",
    "    dst = img.copy()\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            if(cr[i,j]>135 and cr[i,j]<175 and cb[i,j]>77 and cb[i,j]<127):\n",
    "                dst[i,j] = (255,255,255)\n",
    "            else:\n",
    "                dst[i,j] = (0,0,0)\n",
    "                \n",
    "    cv2.imshow('dst',dst)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return dst\n",
    "\n",
    "YCrCb_CrCb(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 肤色检测 基于YCrCb颜色空间的Cr分量+Otsu法阈值分割算法\n",
    "def YCrCb_OTSU(img):\n",
    "    start = time.time()\n",
    "    ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  \n",
    "    (y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "\n",
    "    # 高斯滤波, cr 是待滤波的源图像数据, (5,5)是值窗口大小, 0 是指根据窗口大小来计算高斯函数标准差\n",
    "    cr1 = cv2.GaussianBlur(cr, (5, 5), 0) # 对cr通道分量进行高斯滤波\n",
    "    # 根据OTSU算法求图像阈值, 对图像进行二值化\n",
    "    th, skin = cv2.threshold(cr1, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU) \n",
    "    end = time.time()\n",
    "    print(\"阈值为\"+str(th))\n",
    "    print(\"耗时\"+str(end-start)+\"秒\")\n",
    "    cv2.imshow(\"image CR\", cr1)\n",
    "    cv2.imshow(\"Skin Cr+OSTU\", skin )\n",
    "    cv2.waitKey(0)\n",
    "    return skin\n",
    "\n",
    "\n",
    "#YCrCb_OTSU(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制YCrCb颜色空间图像\n",
    "ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  \n",
    "(y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "\n",
    "fig, axs = plt.subplots(1, 4, figsize=(10,10))          # 创建1X4的网格，其中每个子图大小为7X7 英寸：\n",
    "\n",
    "plt.subplot(1,4,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"原图\")                                       # 为第一个子图添加标题\n",
    "plt.xticks([])  #去掉横坐标值\n",
    "plt.yticks([])  #去掉纵坐标值\n",
    "plt.show\n",
    "\n",
    "plt.subplot(1,4,2)\n",
    "plt.imshow(y,cmap='Greys_r')\n",
    "plt.title(\"y分量\")                                       \n",
    "plt.xticks([])  #去掉横坐标值\n",
    "plt.yticks([])  #去掉纵坐标值\n",
    "plt.show\n",
    "\n",
    "plt.subplot(1,4,3)\n",
    "plt.imshow(cr,cmap='Greys_r')\n",
    "plt.title(\"Cr分量\")                                       \n",
    "plt.xticks([])  #去掉横坐标值\n",
    "plt.yticks([])  #去掉纵坐标值\n",
    "plt.show\n",
    "\n",
    "plt.subplot(1,4,4)\n",
    "plt.imshow(cb,cmap='Greys_r')\n",
    "plt.title(\"Cb分量\")  \n",
    "plt.xticks([])  #去掉横坐标值\n",
    "plt.yticks([])  #去掉纵坐标值\n",
    "plt.show\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 像素分布概率直方图\n",
    "def showimg_pro_eachgray(img):                                          # 显示每一个灰度级的像素数概率\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                          # 灰度化处理\n",
    "          \n",
    "    pixels = cv2.calcHist([img], [0], None, [256], [0, 256])            # 计算每个灰度级中所含像素数，返回的是一个（256,1）的数组\n",
    "    p = pixels / (img.shape[0] * img.shape[1])                          # 获得每个灰度级中像素数占总像素数比例则我们获得了pi的一个向量\n",
    "    x = np.linspace(0, 255, 256)                                        # 横坐标灰度级别\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.imshow(img,'gray')                                              # 如果不加gray就会出现以前hsv与rgb的问题\n",
    "    plt.title('origin image')\n",
    "    plt.colorbar(orientation=\"horizontal\")                              # 水平放置颜色条\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.bar(x, p.ravel(), 0.9, alpha=1, color='b')\n",
    "    plt.title('Histogram of the probablity for each gray level',y=-0.4) # 调节标题上下移动的方法\n",
    "    plt.show()\n",
    "\n",
    "showimg_pro_eachgray(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次找到最佳阈值1,最大类间方差为[21.49265152]\n",
      "第2次找到最佳阈值2,最大类间方差为[28.60677287]\n",
      "第3次找到最佳阈值3,最大类间方差为[36.34682459]\n",
      "第4次找到最佳阈值4,最大类间方差为[45.03307132]\n",
      "第5次找到最佳阈值5,最大类间方差为[55.50225459]\n",
      "第6次找到最佳阈值6,最大类间方差为[67.07035141]\n",
      "第7次找到最佳阈值7,最大类间方差为[80.02348912]\n",
      "第8次找到最佳阈值8,最大类间方差为[93.62067965]\n",
      "第9次找到最佳阈值9,最大类间方差为[106.9080899]\n",
      "第10次找到最佳阈值10,最大类间方差为[121.15393796]\n",
      "第11次找到最佳阈值11,最大类间方差为[136.14607301]\n",
      "第12次找到最佳阈值12,最大类间方差为[151.53217036]\n",
      "第13次找到最佳阈值13,最大类间方差为[167.50235512]\n",
      "第14次找到最佳阈值14,最大类间方差为[183.80305796]\n",
      "第15次找到最佳阈值15,最大类间方差为[199.11770037]\n",
      "第16次找到最佳阈值16,最大类间方差为[215.65910801]\n",
      "第17次找到最佳阈值17,最大类间方差为[231.30850849]\n",
      "第18次找到最佳阈值18,最大类间方差为[247.02546784]\n",
      "第19次找到最佳阈值19,最大类间方差为[262.36655873]\n",
      "第20次找到最佳阈值20,最大类间方差为[278.66326728]\n",
      "第21次找到最佳阈值21,最大类间方差为[294.44601093]\n",
      "第22次找到最佳阈值22,最大类间方差为[310.37876774]\n",
      "第23次找到最佳阈值23,最大类间方差为[327.62971584]\n",
      "第24次找到最佳阈值24,最大类间方差为[344.3554747]\n",
      "第25次找到最佳阈值25,最大类间方差为[361.01459023]\n",
      "第26次找到最佳阈值26,最大类间方差为[377.07501596]\n",
      "第27次找到最佳阈值27,最大类间方差为[393.9586432]\n",
      "第28次找到最佳阈值28,最大类间方差为[411.17167494]\n",
      "第29次找到最佳阈值29,最大类间方差为[428.35365403]\n",
      "第30次找到最佳阈值30,最大类间方差为[446.76221486]\n",
      "第31次找到最佳阈值31,最大类间方差为[463.90735634]\n",
      "第32次找到最佳阈值32,最大类间方差为[481.19416223]\n",
      "第33次找到最佳阈值33,最大类间方差为[498.70556839]\n",
      "第34次找到最佳阈值34,最大类间方差为[517.07424625]\n",
      "第35次找到最佳阈值35,最大类间方差为[536.65499622]\n",
      "第36次找到最佳阈值36,最大类间方差为[554.77760913]\n",
      "第37次找到最佳阈值37,最大类间方差为[574.32680264]\n",
      "第38次找到最佳阈值38,最大类间方差为[594.6986934]\n",
      "第39次找到最佳阈值39,最大类间方差为[615.10740576]\n",
      "第40次找到最佳阈值40,最大类间方差为[634.9153642]\n",
      "第41次找到最佳阈值41,最大类间方差为[654.1874371]\n",
      "第42次找到最佳阈值42,最大类间方差为[674.39060416]\n",
      "第43次找到最佳阈值43,最大类间方差为[694.92333796]\n",
      "第44次找到最佳阈值44,最大类间方差为[716.83046001]\n",
      "第45次找到最佳阈值45,最大类间方差为[739.23944336]\n",
      "第46次找到最佳阈值46,最大类间方差为[761.64056085]\n",
      "第47次找到最佳阈值47,最大类间方差为[782.44783847]\n",
      "第48次找到最佳阈值48,最大类间方差为[802.36146988]\n",
      "第49次找到最佳阈值49,最大类间方差为[822.72491954]\n",
      "第50次找到最佳阈值50,最大类间方差为[843.68063105]\n",
      "第51次找到最佳阈值51,最大类间方差为[865.33614542]\n",
      "第52次找到最佳阈值52,最大类间方差为[888.1932148]\n",
      "第53次找到最佳阈值53,最大类间方差为[915.3518989]\n",
      "第54次找到最佳阈值54,最大类间方差为[940.62992371]\n",
      "第55次找到最佳阈值55,最大类间方差为[968.92793444]\n",
      "第56次找到最佳阈值56,最大类间方差为[998.61536657]\n",
      "第57次找到最佳阈值57,最大类间方差为[1025.75742687]\n",
      "第58次找到最佳阈值58,最大类间方差为[1054.6911951]\n",
      "第59次找到最佳阈值59,最大类间方差为[1081.97610894]\n",
      "第60次找到最佳阈值60,最大类间方差为[1109.42047797]\n",
      "第61次找到最佳阈值61,最大类间方差为[1134.76343623]\n",
      "第62次找到最佳阈值62,最大类间方差为[1159.38870721]\n",
      "第63次找到最佳阈值63,最大类间方差为[1183.58084961]\n",
      "第64次找到最佳阈值64,最大类间方差为[1206.34803606]\n",
      "第65次找到最佳阈值65,最大类间方差为[1227.22501159]\n",
      "第66次找到最佳阈值66,最大类间方差为[1247.1508855]\n",
      "第67次找到最佳阈值67,最大类间方差为[1266.78929232]\n",
      "第68次找到最佳阈值68,最大类间方差为[1285.72175114]\n",
      "第69次找到最佳阈值69,最大类间方差为[1303.78879825]\n",
      "第70次找到最佳阈值70,最大类间方差为[1320.54148304]\n",
      "第71次找到最佳阈值71,最大类间方差为[1337.24605441]\n",
      "第72次找到最佳阈值72,最大类间方差为[1351.8844813]\n",
      "第73次找到最佳阈值73,最大类间方差为[1366.32815921]\n",
      "第74次找到最佳阈值74,最大类间方差为[1379.96579723]\n",
      "第75次找到最佳阈值75,最大类间方差为[1393.23663991]\n",
      "第76次找到最佳阈值76,最大类间方差为[1405.76230391]\n",
      "第77次找到最佳阈值77,最大类间方差为[1417.569685]\n",
      "第78次找到最佳阈值78,最大类间方差为[1428.55542067]\n",
      "第79次找到最佳阈值79,最大类间方差为[1439.13189774]\n",
      "第80次找到最佳阈值80,最大类间方差为[1448.59644312]\n",
      "第81次找到最佳阈值81,最大类间方差为[1458.04779996]\n",
      "第82次找到最佳阈值82,最大类间方差为[1466.64233993]\n",
      "第83次找到最佳阈值83,最大类间方差为[1475.00457688]\n",
      "第84次找到最佳阈值84,最大类间方差为[1482.57761273]\n",
      "第85次找到最佳阈值85,最大类间方差为[1489.74416534]\n",
      "第86次找到最佳阈值86,最大类间方差为[1496.28779894]\n",
      "第87次找到最佳阈值87,最大类间方差为[1502.25748626]\n",
      "第88次找到最佳阈值88,最大类间方差为[1507.64979641]\n",
      "第89次找到最佳阈值89,最大类间方差为[1512.39970023]\n",
      "第90次找到最佳阈值90,最大类间方差为[1516.72769659]\n",
      "第91次找到最佳阈值91,最大类间方差为[1520.57140215]\n",
      "第92次找到最佳阈值92,最大类间方差为[1524.01576997]\n",
      "第93次找到最佳阈值93,最大类间方差为[1527.05241227]\n",
      "第94次找到最佳阈值94,最大类间方差为[1529.6246044]\n",
      "第95次找到最佳阈值95,最大类间方差为[1531.83525839]\n",
      "第96次找到最佳阈值96,最大类间方差为[1533.62266649]\n",
      "第97次找到最佳阈值97,最大类间方差为[1534.92084154]\n",
      "第98次找到最佳阈值98,最大类间方差为[1535.76849072]\n",
      "第99次找到最佳阈值99,最大类间方差为[1536.14813556]\n",
      "第1次找到最佳阈值1,最大类间方差为[21.49265152]\n",
      "第2次找到最佳阈值2,最大类间方差为[28.60677287]\n",
      "第3次找到最佳阈值3,最大类间方差为[36.34682459]\n",
      "第4次找到最佳阈值4,最大类间方差为[45.03307132]\n",
      "第5次找到最佳阈值5,最大类间方差为[55.50225459]\n",
      "第6次找到最佳阈值6,最大类间方差为[67.07035141]\n",
      "第7次找到最佳阈值7,最大类间方差为[80.02348912]\n",
      "第8次找到最佳阈值8,最大类间方差为[93.62067965]\n",
      "第9次找到最佳阈值9,最大类间方差为[106.9080899]\n",
      "第10次找到最佳阈值10,最大类间方差为[121.15393796]\n",
      "第11次找到最佳阈值11,最大类间方差为[136.14607301]\n",
      "第12次找到最佳阈值12,最大类间方差为[151.53217036]\n",
      "第13次找到最佳阈值13,最大类间方差为[167.50235512]\n",
      "第14次找到最佳阈值14,最大类间方差为[183.80305796]\n",
      "第15次找到最佳阈值15,最大类间方差为[199.11770037]\n",
      "第16次找到最佳阈值16,最大类间方差为[215.65910801]\n",
      "第17次找到最佳阈值17,最大类间方差为[231.30850849]\n",
      "第18次找到最佳阈值18,最大类间方差为[247.02546784]\n",
      "第19次找到最佳阈值19,最大类间方差为[262.36655873]\n",
      "第20次找到最佳阈值20,最大类间方差为[278.66326728]\n",
      "第21次找到最佳阈值21,最大类间方差为[294.44601093]\n",
      "第22次找到最佳阈值22,最大类间方差为[310.37876774]\n",
      "第23次找到最佳阈值23,最大类间方差为[327.62971584]\n",
      "第24次找到最佳阈值24,最大类间方差为[344.3554747]\n",
      "第25次找到最佳阈值25,最大类间方差为[361.01459023]\n",
      "第26次找到最佳阈值26,最大类间方差为[377.07501596]\n",
      "第27次找到最佳阈值27,最大类间方差为[393.9586432]\n",
      "第28次找到最佳阈值28,最大类间方差为[411.17167494]\n",
      "第29次找到最佳阈值29,最大类间方差为[428.35365403]\n",
      "第30次找到最佳阈值30,最大类间方差为[446.76221486]\n",
      "第31次找到最佳阈值31,最大类间方差为[463.90735634]\n",
      "第32次找到最佳阈值32,最大类间方差为[481.19416223]\n",
      "第33次找到最佳阈值33,最大类间方差为[498.70556839]\n",
      "第34次找到最佳阈值34,最大类间方差为[517.07424625]\n",
      "第35次找到最佳阈值35,最大类间方差为[536.65499622]\n",
      "第36次找到最佳阈值36,最大类间方差为[554.77760913]\n",
      "第37次找到最佳阈值37,最大类间方差为[574.32680264]\n",
      "第38次找到最佳阈值38,最大类间方差为[594.6986934]\n",
      "第39次找到最佳阈值39,最大类间方差为[615.10740576]\n",
      "第40次找到最佳阈值40,最大类间方差为[634.9153642]\n",
      "第41次找到最佳阈值41,最大类间方差为[654.1874371]\n",
      "第42次找到最佳阈值42,最大类间方差为[674.39060416]\n",
      "第43次找到最佳阈值43,最大类间方差为[694.92333796]\n",
      "第44次找到最佳阈值44,最大类间方差为[716.83046001]\n",
      "第45次找到最佳阈值45,最大类间方差为[739.23944336]\n",
      "第46次找到最佳阈值46,最大类间方差为[761.64056085]\n",
      "第47次找到最佳阈值47,最大类间方差为[782.44783847]\n",
      "第48次找到最佳阈值48,最大类间方差为[802.36146988]\n",
      "第49次找到最佳阈值49,最大类间方差为[822.72491954]\n",
      "第50次找到最佳阈值50,最大类间方差为[843.68063105]\n",
      "第51次找到最佳阈值51,最大类间方差为[865.33614542]\n",
      "第52次找到最佳阈值52,最大类间方差为[888.1932148]\n",
      "第53次找到最佳阈值53,最大类间方差为[915.3518989]\n",
      "第54次找到最佳阈值54,最大类间方差为[940.62992371]\n",
      "第55次找到最佳阈值55,最大类间方差为[968.92793444]\n",
      "第56次找到最佳阈值56,最大类间方差为[998.61536657]\n",
      "第57次找到最佳阈值57,最大类间方差为[1025.75742687]\n",
      "第58次找到最佳阈值58,最大类间方差为[1054.6911951]\n",
      "第59次找到最佳阈值59,最大类间方差为[1081.97610894]\n",
      "第60次找到最佳阈值60,最大类间方差为[1109.42047797]\n",
      "第61次找到最佳阈值61,最大类间方差为[1134.76343623]\n",
      "第62次找到最佳阈值62,最大类间方差为[1159.38870721]\n",
      "第63次找到最佳阈值63,最大类间方差为[1183.58084961]\n",
      "第64次找到最佳阈值64,最大类间方差为[1206.34803606]\n",
      "第65次找到最佳阈值65,最大类间方差为[1227.22501159]\n",
      "第66次找到最佳阈值66,最大类间方差为[1247.1508855]\n",
      "第67次找到最佳阈值67,最大类间方差为[1266.78929232]\n",
      "第68次找到最佳阈值68,最大类间方差为[1285.72175114]\n",
      "第69次找到最佳阈值69,最大类间方差为[1303.78879825]\n",
      "第70次找到最佳阈值70,最大类间方差为[1320.54148304]\n",
      "第71次找到最佳阈值71,最大类间方差为[1337.24605441]\n",
      "第72次找到最佳阈值72,最大类间方差为[1351.8844813]\n",
      "第73次找到最佳阈值73,最大类间方差为[1366.32815921]\n",
      "第74次找到最佳阈值74,最大类间方差为[1379.96579723]\n",
      "第75次找到最佳阈值75,最大类间方差为[1393.23663991]\n",
      "第76次找到最佳阈值76,最大类间方差为[1405.76230391]\n",
      "第77次找到最佳阈值77,最大类间方差为[1417.569685]\n",
      "第78次找到最佳阈值78,最大类间方差为[1428.55542067]\n",
      "第79次找到最佳阈值79,最大类间方差为[1439.13189774]\n",
      "第80次找到最佳阈值80,最大类间方差为[1448.59644312]\n",
      "第81次找到最佳阈值81,最大类间方差为[1458.04779996]\n",
      "第82次找到最佳阈值82,最大类间方差为[1466.64233993]\n",
      "第83次找到最佳阈值83,最大类间方差为[1475.00457688]\n",
      "第84次找到最佳阈值84,最大类间方差为[1482.57761273]\n",
      "第85次找到最佳阈值85,最大类间方差为[1489.74416534]\n",
      "第86次找到最佳阈值86,最大类间方差为[1496.28779894]\n",
      "第87次找到最佳阈值87,最大类间方差为[1502.25748626]\n",
      "第88次找到最佳阈值88,最大类间方差为[1507.64979641]\n",
      "第89次找到最佳阈值89,最大类间方差为[1512.39970023]\n",
      "第90次找到最佳阈值90,最大类间方差为[1516.72769659]\n",
      "第91次找到最佳阈值91,最大类间方差为[1520.57140215]\n",
      "第92次找到最佳阈值92,最大类间方差为[1524.01576997]\n",
      "第93次找到最佳阈值93,最大类间方差为[1527.05241227]\n",
      "第94次找到最佳阈值94,最大类间方差为[1529.6246044]\n",
      "第95次找到最佳阈值95,最大类间方差为[1531.83525839]\n",
      "第96次找到最佳阈值96,最大类间方差为[1533.62266649]\n",
      "第97次找到最佳阈值97,最大类间方差为[1534.92084154]\n",
      "第98次找到最佳阈值98,最大类间方差为[1535.76849072]\n",
      "第99次找到最佳阈值99,最大类间方差为[1536.14813556]\n",
      "最佳阈值是99 最大方差为[1536.14813556]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yehui_PC\\AppData\\Local\\Temp\\ipykernel_12200\\3192852660.py:14: RuntimeWarning: invalid value encountered in divide\n",
      "  m1 = np.dot(x[0:k1],p[0:k1])/p1\n",
      "C:\\Users\\Yehui_PC\\AppData\\Local\\Temp\\ipykernel_12200\\3192852660.py:15: RuntimeWarning: invalid value encountered in divide\n",
      "  m2 = np.dot(x[k1:256],p[k1:256])/p2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次找到最佳阈值117,最大类间方差为[0.02829512]\n",
      "第2次找到最佳阈值118,最大类间方差为[0.50071363]\n",
      "第3次找到最佳阈值119,最大类间方差为[1.35468985]\n",
      "第4次找到最佳阈值120,最大类间方差为[2.73711452]\n",
      "第5次找到最佳阈值121,最大类间方差为[5.72732722]\n",
      "第6次找到最佳阈值122,最大类间方差为[12.62638003]\n",
      "第7次找到最佳阈值123,最大类间方差为[17.3943432]\n",
      "第8次找到最佳阈值124,最大类间方差为[20.11070033]\n",
      "第9次找到最佳阈值125,最大类间方差为[22.13337042]\n",
      "第10次找到最佳阈值126,最大类间方差为[25.22359601]\n",
      "第11次找到最佳阈值127,最大类间方差为[25.87255531]\n",
      "第12次找到最佳阈值128,最大类间方差为[26.31343633]\n",
      "第13次找到最佳阈值129,最大类间方差为[26.87469751]\n",
      "第14次找到最佳阈值130,最大类间方差为[27.68572821]\n",
      "第15次找到最佳阈值131,最大类间方差为[28.49760286]\n",
      "第16次找到最佳阈值132,最大类间方差为[30.00606179]\n",
      "第17次找到最佳阈值133,最大类间方差为[31.17215174]\n",
      "第18次找到最佳阈值134,最大类间方差为[32.29148323]\n",
      "第19次找到最佳阈值135,最大类间方差为[33.46388078]\n",
      "第20次找到最佳阈值136,最大类间方差为[34.94134096]\n",
      "第21次找到最佳阈值137,最大类间方差为[36.6151495]\n",
      "第22次找到最佳阈值138,最大类间方差为[38.98247197]\n",
      "第23次找到最佳阈值139,最大类间方差为[41.44317588]\n",
      "第24次找到最佳阈值140,最大类间方差为[43.9752268]\n",
      "第25次找到最佳阈值141,最大类间方差为[45.75905684]\n",
      "第26次找到最佳阈值142,最大类间方差为[47.05775807]\n",
      "第27次找到最佳阈值143,最大类间方差为[48.02135728]\n",
      "第28次找到最佳阈值144,最大类间方差为[49.89118422]\n",
      "第29次找到最佳阈值145,最大类间方差为[51.22205044]\n",
      "第30次找到最佳阈值146,最大类间方差为[52.43741132]\n",
      "第31次找到最佳阈值147,最大类间方差为[54.04435024]\n",
      "第32次找到最佳阈值148,最大类间方差为[55.44916497]\n",
      "第33次找到最佳阈值149,最大类间方差为[57.27927299]\n",
      "第34次找到最佳阈值150,最大类间方差为[58.70409317]\n",
      "第35次找到最佳阈值151,最大类间方差为[60.01597216]\n",
      "第36次找到最佳阈值152,最大类间方差为[61.18654537]\n",
      "第37次找到最佳阈值153,最大类间方差为[62.67524404]\n",
      "第38次找到最佳阈值154,最大类间方差为[64.40225838]\n",
      "第39次找到最佳阈值155,最大类间方差为[65.837417]\n",
      "第40次找到最佳阈值156,最大类间方差为[67.38741361]\n",
      "第41次找到最佳阈值157,最大类间方差为[68.86982386]\n",
      "第42次找到最佳阈值158,最大类间方差为[69.98547009]\n",
      "第43次找到最佳阈值159,最大类间方差为[71.12712977]\n",
      "第44次找到最佳阈值160,最大类间方差为[72.12971189]\n",
      "第45次找到最佳阈值161,最大类间方差为[72.77789488]\n",
      "第46次找到最佳阈值162,最大类间方差为[73.04331952]\n",
      "第47次找到最佳阈值163,最大类间方差为[73.20784378]\n",
      "第48次找到最佳阈值164,最大类间方差为[73.9244823]\n",
      "第49次找到最佳阈值165,最大类间方差为[75.25383198]\n",
      "第50次找到最佳阈值166,最大类间方差为[76.63798848]\n",
      "第51次找到最佳阈值167,最大类间方差为[77.69225333]\n",
      "第52次找到最佳阈值168,最大类间方差为[78.68363157]\n",
      "第53次找到最佳阈值169,最大类间方差为[80.17771733]\n",
      "第54次找到最佳阈值170,最大类间方差为[82.14225264]\n",
      "第55次找到最佳阈值171,最大类间方差为[84.31161108]\n",
      "第56次找到最佳阈值172,最大类间方差为[86.57581365]\n",
      "第57次找到最佳阈值173,最大类间方差为[89.72607528]\n",
      "第58次找到最佳阈值174,最大类间方差为[94.42624675]\n",
      "第59次找到最佳阈值175,最大类间方差为[101.40892048]\n",
      "第60次找到最佳阈值176,最大类间方差为[107.91106963]\n",
      "第61次找到最佳阈值177,最大类间方差为[112.48575285]\n",
      "第62次找到最佳阈值178,最大类间方差为[115.01037372]\n",
      "第63次找到最佳阈值179,最大类间方差为[116.59019061]\n",
      "第64次找到最佳阈值180,最大类间方差为[117.62508004]\n",
      "第65次找到最佳阈值181,最大类间方差为[118.36258373]\n",
      "第66次找到最佳阈值182,最大类间方差为[118.92233026]\n",
      "第67次找到最佳阈值183,最大类间方差为[119.35597678]\n",
      "第68次找到最佳阈值184,最大类间方差为[119.70905869]\n",
      "第69次找到最佳阈值185,最大类间方差为[119.95225697]\n",
      "第70次找到最佳阈值186,最大类间方差为[120.11426792]\n",
      "第71次找到最佳阈值187,最大类间方差为[120.2422395]\n",
      "第72次找到最佳阈值188,最大类间方差为[120.32742318]\n",
      "第73次找到最佳阈值189,最大类间方差为[120.34767449]\n",
      "耗时6.608487129211426s\n"
     ]
    }
   ],
   "source": [
    "# 基于手动编程的OTSU 实现的YCrCb分割 \n",
    "def OTSU(img):\n",
    "    #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                             # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    pixels = cv2.calcHist([img], [0], None, [256], [0, 256])                # 计算每个灰度级中所含像素数，返回的是一个（256,1）的数组\n",
    "    p = pixels / (img.shape[0] * img.shape[1])                              # 获得每个灰度级中像素数占总像素数比例则我们获得了p_i的一个向量\n",
    "    x=np.linspace(1,256,256)                                                # 灰度级像素范围定义，若定义为0～255，则求平均灰度级时会忽略第一个数据，所以我们定义为从1到256                                                 \n",
    "    maxvar=0\n",
    "    mG = np.sum(x*p)                                                        # 平均灰度级\n",
    "    th=0\n",
    "    step = 0\n",
    "    for k1 in range(1,256):                                                 # 暴力搜索\n",
    "        p1 = np.sum(p[0:k1])\n",
    "        p2 = np.sum(p[k1:256])\n",
    "        m1 = np.dot(x[0:k1],p[0:k1])/p1\n",
    "        m2 = np.dot(x[k1:256],p[k1:256])/p2\n",
    "        vars = p1*p2*(m1-m2)**2\n",
    "        if(vars>maxvar):\n",
    "            maxvar = vars\n",
    "            th = k1\n",
    "            step = step+1\n",
    "            print(\"第\"+str(step)+\"次找到最佳阈值\"+str(th)+\",\"+\"最大类间方差为\"+str(maxvar))\n",
    "    return th,maxvar \n",
    "print(\"最佳阈值是\"+str(OTSU(img)[0]),\"最大方差为\"+str(OTSU(img)[1]))\n",
    "\n",
    "\n",
    "# 基于手动编程的OTSU 实现的YCrCb分割                  # 凸显改进算法的优越性，使用mopi.jpeg例子，能良好体现出改进之后的算法，具有更强的识别效果，在处理肤色相近，像素值集中的图像时更占上风\n",
    "def YCrCb_OTSU(img):\n",
    "    start  = time.time()                               # 引入计时模块\n",
    "    img = Hist_equalization_Cr(img)\n",
    "    ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  有没有转换公式呢？\n",
    "    (y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "    cr1 = cv2.GaussianBlur(cr, (5, 5), 0) # # 高斯滤波, cr 是待滤波的源图像数据, (5,5)是值窗口大小, 0 是指根据窗口大小来计算高斯函数标准差\n",
    "    th = OTSU(cr1)[0]\n",
    "    skin = cr1.copy()\n",
    "    # 根据OTSU算法求图像阈值, 对图像进行二值化 获得人脸部分（白色）,会发现因为手部与脸部肤色相近，故被认定为前景（人脸部分）\n",
    "    for i in range(0,img.shape[0]):\n",
    "        for j in range(0,img.shape[1]):\n",
    "            if(cr1[i,j]< th):           \n",
    "                skin[i,j]= 0  \n",
    "            else:  \n",
    "                skin[i,j] = 255\n",
    "\n",
    "    # # 原图的人脸部分\n",
    "    # for i in range(0,img.shape[ßß0]):\n",
    "    #     for j in range(0,img.shape[1]): \n",
    "    #         if(skin[i,j]==0):\n",
    "    #             img[i,j] = 0\n",
    "    # cv2.imshow(\"SKin\",img)\n",
    "    end = time.time()\n",
    "    print(\"耗时\"+str(end-start)+\"s\")\n",
    "    # 显示图像\n",
    "    cv2.imshow(\"Skin Cr+OSTU_Hand\", skin) # 因为通过对YCrCb空间分割再还原RGB比较麻烦\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "YCrCb_OTSU(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OTSU法实现图像分割\n",
    "def OTSU_Seg(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                             # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    _, obj = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # cv2.imshow(\"img\",img)\n",
    "    # cv2.imshow(\"Use_OTSU_Seg\",obj)\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return obj\n",
    "\n",
    "obj = OTSU_Seg(img)  \n",
    "#figure()\n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,14))          # 创建1X2的网格，其中每个子图大小为14X14 英寸：\n",
    "plt.subplot(1,2,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"Lena.jpg\")                                       # 为第一个子图添加标题\n",
    "\n",
    "plt.subplot(1,2,2)                                      # 占据第二个位置\n",
    "plt.imshow(obj,cmap='Greys_r')                          # plt默认显示三通道图像\n",
    "plt.title(\"调用threshold函数+OTSU阈值分割后\")                              # 为第一个子图添加标题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手撸OTSU实现图像分割\n",
    "def OTSU_Seg_Hand(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                             # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    th = OTSU(img)[0]\n",
    "    for i in range(0,img.shape[0]):\n",
    "        for j in range(0,img.shape[1]):     \n",
    "            if(img[i,j]<th):\n",
    "                img[i,j]=0\n",
    "            else:\n",
    "                img[i,j]=255\n",
    "    return img \n",
    "obj = OTSU_Seg_Hand(img)  \n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,14))          # 创建1X2的网格，其中每个子图大小为14X14 英寸：\n",
    "plt.subplot(1,2,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"Cameraman.jpg\")                                       # 为第一个子图添加标题\n",
    "\n",
    "plt.subplot(1,2,2)                                      # 占据第二个位置\n",
    "plt.imshow(obj,cmap='Greys_r')                          # plt默认显示三通道图像\n",
    "plt.title(\"使用手撸OTSU法阈值分割后\")                              # 为第一个子图添加标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次找到最佳阈值1,最大类间方差为[1.41485331e-05]\n",
      "第2次找到最佳阈值2,最大类间方差为[1.88317329e-05]\n",
      "第3次找到最佳阈值3,最大类间方差为[2.39269804e-05]\n",
      "第4次找到最佳阈值4,最大类间方差为[2.96451045e-05]\n",
      "第5次找到最佳阈值5,最大类间方差为[3.65369292e-05]\n",
      "第6次找到最佳阈值6,最大类间方差为[4.41521646e-05]\n",
      "第7次找到最佳阈值7,最大类间方差为[5.26791673e-05]\n",
      "第8次找到最佳阈值8,最大类间方差为[6.16301476e-05]\n",
      "第9次找到最佳阈值9,最大类间方差为[7.03772007e-05]\n",
      "第10次找到最佳阈值10,最大类间方差为[7.97551899e-05]\n",
      "第11次找到最佳阈值11,最大类间方差为[8.9624457e-05]\n",
      "第12次找到最佳阈值12,最大类间方差为[9.97530681e-05]\n",
      "第13次找到最佳阈值13,最大类间方差为[0.00011027]\n",
      "第14次找到最佳阈值14,最大类间方差为[0.000121]\n",
      "第15次找到最佳阈值15,最大类间方差为[0.00013108]\n",
      "第16次找到最佳阈值16,最大类间方差为[0.00014197]\n",
      "第17次找到最佳阈值17,最大类间方差为[0.00015227]\n",
      "第18次找到最佳阈值18,最大类间方差为[0.00016262]\n",
      "第19次找到最佳阈值19,最大类间方差为[0.00017271]\n",
      "第20次找到最佳阈值20,最大类间方差为[0.00018344]\n",
      "第21次找到最佳阈值21,最大类间方差为[0.00019383]\n",
      "第22次找到最佳阈值22,最大类间方差为[0.00020432]\n",
      "第23次找到最佳阈值23,最大类间方差为[0.00021568]\n",
      "第24次找到最佳阈值24,最大类间方差为[0.00022669]\n",
      "第25次找到最佳阈值25,最大类间方差为[0.00023765]\n",
      "第26次找到最佳阈值26,最大类间方差为[0.00024823]\n",
      "第27次找到最佳阈值27,最大类间方差为[0.00025934]\n",
      "第28次找到最佳阈值28,最大类间方差为[0.00027067]\n",
      "第29次找到最佳阈值29,最大类间方差为[0.00028198]\n",
      "第30次找到最佳阈值30,最大类间方差为[0.0002941]\n",
      "第31次找到最佳阈值31,最大类间方差为[0.00030539]\n",
      "第32次找到最佳阈值32,最大类间方差为[0.00031677]\n",
      "第33次找到最佳阈值33,最大类间方差为[0.0003283]\n",
      "第34次找到最佳阈值34,最大类间方差为[0.00034039]\n",
      "第35次找到最佳阈值35,最大类间方差为[0.00035328]\n",
      "第36次找到最佳阈值36,最大类间方差为[0.00036521]\n",
      "第37次找到最佳阈值37,最大类间方差为[0.00037808]\n",
      "第38次找到最佳阈值38,最大类间方差为[0.00039149]\n",
      "第39次找到最佳阈值39,最大类间方差为[0.00040492]\n",
      "第40次找到最佳阈值40,最大类间方差为[0.00041796]\n",
      "第41次找到最佳阈值41,最大类间方差为[0.00043065]\n",
      "第42次找到最佳阈值42,最大类间方差为[0.00044395]\n",
      "第43次找到最佳阈值43,最大类间方差为[0.00045747]\n",
      "第44次找到最佳阈值44,最大类间方差为[0.00047189]\n",
      "第45次找到最佳阈值45,最大类间方差为[0.00048664]\n",
      "第46次找到最佳阈值46,最大类间方差为[0.00050139]\n",
      "第47次找到最佳阈值47,最大类间方差为[0.00051508]\n",
      "第48次找到最佳阈值48,最大类间方差为[0.00052819]\n",
      "第49次找到最佳阈值49,最大类间方差为[0.0005416]\n",
      "第50次找到最佳阈值50,最大类间方差为[0.00055539]\n",
      "第51次找到最佳阈值51,最大类间方差为[0.00056965]\n",
      "第52次找到最佳阈值52,最大类间方差为[0.00058469]\n",
      "第53次找到最佳阈值53,最大类间方差为[0.00060257]\n",
      "第54次找到最佳阈值54,最大类间方差为[0.00061921]\n",
      "第55次找到最佳阈值55,最大类间方差为[0.00063784]\n",
      "第56次找到最佳阈值56,最大类间方差为[0.00065738]\n",
      "第57次找到最佳阈值57,最大类间方差为[0.00067525]\n",
      "第58次找到最佳阈值58,最大类间方差为[0.0006943]\n",
      "第59次找到最佳阈值59,最大类间方差为[0.00071226]\n",
      "第60次找到最佳阈值60,最大类间方差为[0.00073033]\n",
      "第61次找到最佳阈值61,最大类间方差为[0.00074701]\n",
      "第62次找到最佳阈值62,最大类间方差为[0.00076322]\n",
      "第63次找到最佳阈值63,最大类间方差为[0.00077915]\n",
      "第64次找到最佳阈值64,最大类间方差为[0.00079413]\n",
      "第65次找到最佳阈值65,最大类间方差为[0.00080788]\n",
      "第66次找到最佳阈值66,最大类间方差为[0.00082099]\n",
      "第67次找到最佳阈值67,最大类间方差为[0.00083392]\n",
      "第68次找到最佳阈值68,最大类间方差为[0.00084639]\n",
      "第69次找到最佳阈值69,最大类间方差为[0.00085828]\n",
      "第70次找到最佳阈值70,最大类间方差为[0.00086931]\n",
      "第71次找到最佳阈值71,最大类间方差为[0.0008803]\n",
      "第72次找到最佳阈值72,最大类间方差为[0.00088994]\n",
      "第73次找到最佳阈值73,最大类间方差为[0.00089945]\n",
      "第74次找到最佳阈值74,最大类间方差为[0.00090843]\n",
      "第75次找到最佳阈值75,最大类间方差为[0.00091716]\n",
      "第76次找到最佳阈值76,最大类间方差为[0.00092541]\n",
      "第77次找到最佳阈值77,最大类间方差为[0.00093318]\n",
      "第78次找到最佳阈值78,最大类间方差为[0.00094041]\n",
      "第79次找到最佳阈值79,最大类间方差为[0.00094738]\n",
      "第80次找到最佳阈值80,最大类间方差为[0.00095361]\n",
      "第81次找到最佳阈值81,最大类间方差为[0.00095983]\n",
      "第82次找到最佳阈值82,最大类间方差为[0.00096549]\n",
      "第83次找到最佳阈值83,最大类间方差为[0.00097099]\n",
      "第84次找到最佳阈值84,最大类间方差为[0.00097598]\n",
      "第85次找到最佳阈值85,最大类间方差为[0.00098069]\n",
      "第86次找到最佳阈值86,最大类间方差为[0.000985]\n",
      "第87次找到最佳阈值87,最大类间方差为[0.00098893]\n",
      "第88次找到最佳阈值88,最大类间方差为[0.00099248]\n",
      "第89次找到最佳阈值89,最大类间方差为[0.00099561]\n",
      "第90次找到最佳阈值90,最大类间方差为[0.00099846]\n",
      "第91次找到最佳阈值91,最大类间方差为[0.00100099]\n",
      "第92次找到最佳阈值92,最大类间方差为[0.00100325]\n",
      "第93次找到最佳阈值93,最大类间方差为[0.00100525]\n",
      "第94次找到最佳阈值94,最大类间方差为[0.00100695]\n",
      "第95次找到最佳阈值95,最大类间方差为[0.0010084]\n",
      "第96次找到最佳阈值96,最大类间方差为[0.00100958]\n",
      "第97次找到最佳阈值97,最大类间方差为[0.00101043]\n",
      "第98次找到最佳阈值98,最大类间方差为[0.00101099]\n",
      "第99次找到最佳阈值99,最大类间方差为[0.00101124]\n",
      "第1次找到最佳阈值1,最大类间方差为[1.41485331e-05]\n",
      "第2次找到最佳阈值2,最大类间方差为[1.88317329e-05]\n",
      "第3次找到最佳阈值3,最大类间方差为[2.39269804e-05]\n",
      "第4次找到最佳阈值4,最大类间方差为[2.96451045e-05]\n",
      "第5次找到最佳阈值5,最大类间方差为[3.65369292e-05]\n",
      "第6次找到最佳阈值6,最大类间方差为[4.41521646e-05]\n",
      "第7次找到最佳阈值7,最大类间方差为[5.26791673e-05]\n",
      "第8次找到最佳阈值8,最大类间方差为[6.16301476e-05]\n",
      "第9次找到最佳阈值9,最大类间方差为[7.03772007e-05]\n",
      "第10次找到最佳阈值10,最大类间方差为[7.97551899e-05]\n",
      "第11次找到最佳阈值11,最大类间方差为[8.9624457e-05]\n",
      "第12次找到最佳阈值12,最大类间方差为[9.97530681e-05]\n",
      "第13次找到最佳阈值13,最大类间方差为[0.00011027]\n",
      "第14次找到最佳阈值14,最大类间方差为[0.000121]\n",
      "第15次找到最佳阈值15,最大类间方差为[0.00013108]\n",
      "第16次找到最佳阈值16,最大类间方差为[0.00014197]\n",
      "第17次找到最佳阈值17,最大类间方差为[0.00015227]\n",
      "第18次找到最佳阈值18,最大类间方差为[0.00016262]\n",
      "第19次找到最佳阈值19,最大类间方差为[0.00017271]\n",
      "第20次找到最佳阈值20,最大类间方差为[0.00018344]\n",
      "第21次找到最佳阈值21,最大类间方差为[0.00019383]\n",
      "第22次找到最佳阈值22,最大类间方差为[0.00020432]\n",
      "第23次找到最佳阈值23,最大类间方差为[0.00021568]\n",
      "第24次找到最佳阈值24,最大类间方差为[0.00022669]\n",
      "第25次找到最佳阈值25,最大类间方差为[0.00023765]\n",
      "第26次找到最佳阈值26,最大类间方差为[0.00024823]\n",
      "第27次找到最佳阈值27,最大类间方差为[0.00025934]\n",
      "第28次找到最佳阈值28,最大类间方差为[0.00027067]\n",
      "第29次找到最佳阈值29,最大类间方差为[0.00028198]\n",
      "第30次找到最佳阈值30,最大类间方差为[0.0002941]\n",
      "第31次找到最佳阈值31,最大类间方差为[0.00030539]\n",
      "第32次找到最佳阈值32,最大类间方差为[0.00031677]\n",
      "第33次找到最佳阈值33,最大类间方差为[0.0003283]\n",
      "第34次找到最佳阈值34,最大类间方差为[0.00034039]\n",
      "第35次找到最佳阈值35,最大类间方差为[0.00035328]\n",
      "第36次找到最佳阈值36,最大类间方差为[0.00036521]\n",
      "第37次找到最佳阈值37,最大类间方差为[0.00037808]\n",
      "第38次找到最佳阈值38,最大类间方差为[0.00039149]\n",
      "第39次找到最佳阈值39,最大类间方差为[0.00040492]\n",
      "第40次找到最佳阈值40,最大类间方差为[0.00041796]\n",
      "第41次找到最佳阈值41,最大类间方差为[0.00043065]\n",
      "第42次找到最佳阈值42,最大类间方差为[0.00044395]\n",
      "第43次找到最佳阈值43,最大类间方差为[0.00045747]\n",
      "第44次找到最佳阈值44,最大类间方差为[0.00047189]\n",
      "第45次找到最佳阈值45,最大类间方差为[0.00048664]\n",
      "第46次找到最佳阈值46,最大类间方差为[0.00050139]\n",
      "第47次找到最佳阈值47,最大类间方差为[0.00051508]\n",
      "第48次找到最佳阈值48,最大类间方差为[0.00052819]\n",
      "第49次找到最佳阈值49,最大类间方差为[0.0005416]\n",
      "第50次找到最佳阈值50,最大类间方差为[0.00055539]\n",
      "第51次找到最佳阈值51,最大类间方差为[0.00056965]\n",
      "第52次找到最佳阈值52,最大类间方差为[0.00058469]\n",
      "第53次找到最佳阈值53,最大类间方差为[0.00060257]\n",
      "第54次找到最佳阈值54,最大类间方差为[0.00061921]\n",
      "第55次找到最佳阈值55,最大类间方差为[0.00063784]\n",
      "第56次找到最佳阈值56,最大类间方差为[0.00065738]\n",
      "第57次找到最佳阈值57,最大类间方差为[0.00067525]\n",
      "第58次找到最佳阈值58,最大类间方差为[0.0006943]\n",
      "第59次找到最佳阈值59,最大类间方差为[0.00071226]\n",
      "第60次找到最佳阈值60,最大类间方差为[0.00073033]\n",
      "第61次找到最佳阈值61,最大类间方差为[0.00074701]\n",
      "第62次找到最佳阈值62,最大类间方差为[0.00076322]\n",
      "第63次找到最佳阈值63,最大类间方差为[0.00077915]\n",
      "第64次找到最佳阈值64,最大类间方差为[0.00079413]\n",
      "第65次找到最佳阈值65,最大类间方差为[0.00080788]\n",
      "第66次找到最佳阈值66,最大类间方差为[0.00082099]\n",
      "第67次找到最佳阈值67,最大类间方差为[0.00083392]\n",
      "第68次找到最佳阈值68,最大类间方差为[0.00084639]\n",
      "第69次找到最佳阈值69,最大类间方差为[0.00085828]\n",
      "第70次找到最佳阈值70,最大类间方差为[0.00086931]\n",
      "第71次找到最佳阈值71,最大类间方差为[0.0008803]\n",
      "第72次找到最佳阈值72,最大类间方差为[0.00088994]\n",
      "第73次找到最佳阈值73,最大类间方差为[0.00089945]\n",
      "第74次找到最佳阈值74,最大类间方差为[0.00090843]\n",
      "第75次找到最佳阈值75,最大类间方差为[0.00091716]\n",
      "第76次找到最佳阈值76,最大类间方差为[0.00092541]\n",
      "第77次找到最佳阈值77,最大类间方差为[0.00093318]\n",
      "第78次找到最佳阈值78,最大类间方差为[0.00094041]\n",
      "第79次找到最佳阈值79,最大类间方差为[0.00094738]\n",
      "第80次找到最佳阈值80,最大类间方差为[0.00095361]\n",
      "第81次找到最佳阈值81,最大类间方差为[0.00095983]\n",
      "第82次找到最佳阈值82,最大类间方差为[0.00096549]\n",
      "第83次找到最佳阈值83,最大类间方差为[0.00097099]\n",
      "第84次找到最佳阈值84,最大类间方差为[0.00097598]\n",
      "第85次找到最佳阈值85,最大类间方差为[0.00098069]\n",
      "第86次找到最佳阈值86,最大类间方差为[0.000985]\n",
      "第87次找到最佳阈值87,最大类间方差为[0.00098893]\n",
      "第88次找到最佳阈值88,最大类间方差为[0.00099248]\n",
      "第89次找到最佳阈值89,最大类间方差为[0.00099561]\n",
      "第90次找到最佳阈值90,最大类间方差为[0.00099846]\n",
      "第91次找到最佳阈值91,最大类间方差为[0.00100099]\n",
      "第92次找到最佳阈值92,最大类间方差为[0.00100325]\n",
      "第93次找到最佳阈值93,最大类间方差为[0.00100525]\n",
      "第94次找到最佳阈值94,最大类间方差为[0.00100695]\n",
      "第95次找到最佳阈值95,最大类间方差为[0.0010084]\n",
      "第96次找到最佳阈值96,最大类间方差为[0.00100958]\n",
      "第97次找到最佳阈值97,最大类间方差为[0.00101043]\n",
      "第98次找到最佳阈值98,最大类间方差为[0.00101099]\n",
      "第99次找到最佳阈值99,最大类间方差为[0.00101124]\n",
      "最佳阈值是99 最大方差比为[0.00101124]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yehui_PC\\AppData\\Local\\Temp\\ipykernel_12200\\1733875761.py:19: RuntimeWarning: invalid value encountered in divide\n",
      "  m1 = np.dot(x[0:k1],p[0:k1])/p1\n",
      "C:\\Users\\Yehui_PC\\AppData\\Local\\Temp\\ipykernel_12200\\1733875761.py:20: RuntimeWarning: invalid value encountered in divide\n",
      "  m2 = np.dot(x[k1:256],p[k1:256])/p2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1次找到最佳阈值117,最大类间方差为[9.86514084e-08]\n",
      "第2次找到最佳阈值118,最大类间方差为[1.74574636e-06]\n",
      "第3次找到最佳阈值119,最大类间方差为[4.72314861e-06]\n",
      "第4次找到最佳阈值120,最大类间方差为[9.54299512e-06]\n",
      "第5次找到最佳阈值121,最大类间方差为[1.99684213e-05]\n",
      "第6次找到最佳阈值122,最大类间方差为[4.40220832e-05]\n",
      "第7次找到最佳阈值123,最大类间方差为[6.06456658e-05]\n",
      "第8次找到最佳阈值124,最大类间方差为[7.01162899e-05]\n",
      "第9次找到最佳阈值125,最大类间方差为[7.71683627e-05]\n",
      "第10次找到最佳阈值126,最大类间方差为[8.79424854e-05]\n",
      "第11次找到最佳阈值127,最大类间方差为[9.02050928e-05]\n",
      "第12次找到最佳阈值128,最大类间方差为[9.17422318e-05]\n",
      "第13次找到最佳阈值129,最大类间方差为[9.36990782e-05]\n",
      "第14次找到最佳阈值130,最大类间方差为[9.65267502e-05]\n",
      "第15次找到最佳阈值131,最大类间方差为[9.93573646e-05]\n",
      "第16次找到最佳阈值132,最大类间方差为[0.00010462]\n",
      "第17次找到最佳阈值133,最大类间方差为[0.00010868]\n",
      "第18次找到最佳阈值134,最大类间方差为[0.00011258]\n",
      "第19次找到最佳阈值135,最大类间方差为[0.00011667]\n",
      "第20次找到最佳阈值136,最大类间方差为[0.00012182]\n",
      "第21次找到最佳阈值137,最大类间方差为[0.00012766]\n",
      "第22次找到最佳阈值138,最大类间方差为[0.00013591]\n",
      "第23次找到最佳阈值139,最大类间方差为[0.00014449]\n",
      "第24次找到最佳阈值140,最大类间方差为[0.00015332]\n",
      "第25次找到最佳阈值141,最大类间方差为[0.00015954]\n",
      "第26次找到最佳阈值142,最大类间方差为[0.00016407]\n",
      "第27次找到最佳阈值143,最大类间方差为[0.00016743]\n",
      "第28次找到最佳阈值144,最大类间方差为[0.00017395]\n",
      "第29次找到最佳阈值145,最大类间方差为[0.00017859]\n",
      "第30次找到最佳阈值146,最大类间方差为[0.00018282]\n",
      "第31次找到最佳阈值147,最大类间方差为[0.00018843]\n",
      "第32次找到最佳阈值148,最大类间方差为[0.00019332]\n",
      "第33次找到最佳阈值149,最大类间方差为[0.00019971]\n",
      "第34次找到最佳阈值150,最大类间方差为[0.00020467]\n",
      "第35次找到最佳阈值151,最大类间方差为[0.00020565]\n",
      "耗时2.368887424468994s\n"
     ]
    }
   ],
   "source": [
    "# 基于手撸的OTSU_IMPROVE 实现的YCrCb分割                  \n",
    "# 凸显改进算法的优越性，使用mopi.jpeg例子，能良好体现出改进之后的算法，具有更强的识别效果，在处理肤色相近，像素值集中的图像时更占上风\n",
    "\n",
    "#  手撸实现最大类间类内方差比 \n",
    "def OTSU_IMPROVE(img):\n",
    "    #img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                          # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    pixels = cv2.calcHist([img], [0], None, [256], [0, 256])                # 计算每个灰度级中所含像素数，返回的是一个（256,1）的数组\n",
    "    p = pixels / (img.shape[0] * img.shape[1])                              # 获得每个灰度级中像素数占总像素数比例则我们获得了p_i的一个向量\n",
    "    x=np.linspace(1,256,256)                                                # 灰度级像素范围定义，若定义为0～255，则求平均灰度级时会忽略第一个数据，所以我们定义为从1到256                                                 \n",
    "    sigma_b = 0                                                             # 类间方差\n",
    "    sigma_in = 0                                                            # 类内方差\n",
    "    maxvar = 0                                                              # 最大类间类内方差比\n",
    "    mG = np.sum(x*p)                                                        # 平均灰度级\n",
    "    th=0\n",
    "    step = 0\n",
    "    for k1 in range(1,256):                                                 # 暴力搜索\n",
    "        p1 = np.sum(p[0:k1])\n",
    "        p2 = np.sum(p[k1:256])\n",
    "        m1 = np.dot(x[0:k1],p[0:k1])/p1\n",
    "        m2 = np.dot(x[k1:256],p[k1:256])/p2\n",
    "        vars1 = p1*p2*(m1-m2)**2\n",
    "        if(vars1>sigma_b):\n",
    "            sigma_b = vars1\n",
    "        vars2 = np.sum(p[0:k1]*(x[0:k1]-m1)**2)+np.sum(p[k1:256]*(x[k1:256]-m2)**2)\n",
    "        if(vars2>sigma_in):\n",
    "            sigma_in = vars2\n",
    "        if(sigma_in>0):\n",
    "            vars = sigma_b/sigma_in\n",
    "        else:\n",
    "            vars = 0\n",
    "        if(vars>maxvar):\n",
    "            maxvar = vars\n",
    "            th = k1\n",
    "            step = step + 1\n",
    "            print(\"第\"+str(step)+\"次找到最佳阈值\"+str(th)+\",\"+\"最大类间方差为\"+str(maxvar))\n",
    "    return th,maxvar \n",
    "\n",
    "print(\"最佳阈值是\"+str(OTSU_IMPROVE(img)[0]),\"最大方差比为\"+str(OTSU_IMPROVE(img)[1]))    \n",
    "\n",
    "        \n",
    "def YCrCb_OTSU_IMPROVE(img):\n",
    "    start  = time.time()                               # 引入计时模块\n",
    "    img = Hist_equalization_Cr(img)\n",
    "    ycrcb = cv2.cvtColor(img,cv2.COLOR_BGR2YCrCb)      #   RGB->YCrCb  有没有转换公式呢？\n",
    "    (y,cr,cb) = cv2.split(ycrcb)                       # 图像分割，分别获取y,cr,br通道图像\n",
    "    cr1 = cv2.GaussianBlur(cr, (5, 5), 0) # # 高斯滤波, cr 是待滤波的源图像数据, (5,5)是值窗口大小, 0 是指根据窗口大小来计算高斯函数标准差\n",
    "    th = OTSU_IMPROVE(cr1)[0]\n",
    "    skin = cr1.copy()\n",
    "    # 根据OTSU算法求图像阈值, 对图像进行二值化 获得人脸部分（白色）,会发现因为手部与脸部肤色相近，故被认定为前景（人脸部分）\n",
    "    for i in range(0,img.shape[0]):\n",
    "        for j in range(0,img.shape[1]):\n",
    "            if(cr1[i,j]< th):           \n",
    "                skin[i,j]= 0  \n",
    "            else:  \n",
    "                skin[i,j] = 255\n",
    "\n",
    "    # # 原图的人脸部分\n",
    "    # for i in range(0,img.shape[ßß0]):\n",
    "    #     for j in range(0,img.shape[1]): \n",
    "    #         if(skin[i,j]==0):\n",
    "    #             img[i,j] = 0\n",
    "    # cv2.imshow(\"SKin\",img)\n",
    "    end = time.time()\n",
    "    print(\"耗时\"+str(end-start)+\"s\")\n",
    "    #显示图像\n",
    "    cv2.imshow(\"Skin Cr+OSTU_IMPROVE_Hand\", skin) # 因为通过对YCrCb空间分割再还原RGB比较麻烦\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return skin\n",
    "\n",
    "kernel = np.ones((3,3),np.uint8)   # 定义一个3*3的结构元素\n",
    "skin = YCrCb_OTSU_IMPROVE(img)\n",
    "cv2.imshow(\"skin.jpg\",skin)\n",
    "skin1 = dilate(skin,kernel)\n",
    "cv2.imshow(\"skin1.jpg\",skin1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多阈值分割的OTSU改进算法    用于处理口红色号较深，将口红认定为前景的情况\n",
    "def OTSU_Mult_IMPROVE(img):\n",
    "    pixels = cv2.calcHist([img], [0], None, [256], [0, 256])                # 计算每个灰度级中所含像素数，返回的是一个（256,1）的数组\n",
    "    p = pixels / (img.shape[0] * img.shape[1])                              # 获得每个灰度级中像素数占总像素数比例则我们获得了p_i的一个向量\n",
    "    x=np.linspace(1,256,256)                                                # 灰度级像素范围定义，若定义为0～255，则求平均灰度级时会忽略第一个数据，所以我们定义为从1到256                                                 \n",
    "    sigma_b = 0                                                             # 类间方差\n",
    "    sigma_in = 0                                                            # 类内方差\n",
    "    maxvar = 0                                                              # 最大类间类内方差\n",
    "    mu_T = np.sum(x*p)                                                        # 平均灰度级\n",
    "    th1=0\n",
    "    th2=0\n",
    "    step = 0\n",
    "    for k1 in range(1,256):                                                 # 暴力搜索\n",
    "        for k2 in range(1,256):\n",
    "                a0 = np.sum(p[0:k1])\n",
    "                a1 = np.sum(p[k1:256])\n",
    "                a2 = 1-a0-a1\n",
    "                mu_0 = np.dot(x[0:k1],p[0:k1])/a0\n",
    "                mu_1 = np.dot(x[k1:k2],p[k1:k2])/a1\n",
    "                mu_2 = np.dot(x[k2:256],p[k2:256])/a2\n",
    "                vars1 = a0*(mu_0-mu_T)**2+a1*(mu_1-mu_T)**2+a2*(mu_2-mu_T)**2\n",
    "\n",
    "    return th1,th2,maxvar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YCrCb_OTSU及其改进算法的作图\n",
    "skin1 = YCrCb_OTSU(img)\n",
    "skin2=  YCrCb_OTSU_IMPROVE(img)\n",
    "fig, axs = plt.subplots(1, 3, figsize=(14,14))          # 创建1X2的网格，其中每个子图大小为14X14 英寸：\n",
    "plt.subplot(1,3,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"原图\")                                       # 为第一个子图添加标题\n",
    "\n",
    "plt.subplot(1,3,2)                                      # 占据第二个位置\n",
    "plt.imshow(skin1,cmap='Greys_r')                         \n",
    "plt.title(\"使用手撸OTSU法阈值分割后\")                          \n",
    "\n",
    "plt.subplot(1,3,3)                                      # 占据第三个位置\n",
    "plt.imshow(skin2,cmap='Greys_r')                        \n",
    "plt.title(\"使用YCrCb+改进OTSU法阈值分割后\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 手撸OTSU_IMPROVE实现图像分割\n",
    "def OTSU_Seg_IMPROVE(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)                             # 若待划分的图像是单通道，则无需转为灰度图\n",
    "    th = OTSU_IMPROVE(img)[0]\n",
    "    for i in range(0,img.shape[0]):\n",
    "        for j in range(0,img.shape[1]):     \n",
    "            if(img[i,j]<th):\n",
    "                img[i,j]=0\n",
    "            else:\n",
    "                img[i,j]=255\n",
    "    return img \n",
    "obj = OTSU_Seg_IMPROVE(img)  \n",
    "fig, axs = plt.subplots(1, 2, figsize=(14,14))          # 创建1X2的网格，其中每个子图大小为14X14 英寸：\n",
    "plt.subplot(1,2,1)                                      # 占据第一个位置\n",
    "img_RGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)           # opencv读取的图像是BGR通道的，plt输出时是RGB通道\n",
    "plt.imshow(img_RGB)\n",
    "plt.title(\"Cameraman.jpg\")                                       # 为第一个子图添加标题\n",
    "\n",
    "plt.subplot(1,2,2)                                      # 占据第二个位置\n",
    "plt.imshow(obj,cmap='Greys_r')                          # plt默认显示三通道图像\n",
    "plt.title(\"使用改进的OTSU法阈值分割后\")                              # 为第一个子图添加标题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 二次多项式模式检测\n",
    "def Quad_poly(img):\n",
    "    Info = img.shape\n",
    "    height = Info[0]\n",
    "    width = Info[1]\n",
    "    Channels = Info[2]\n",
    "    # 创建一个与原图像大小相同的零数组\n",
    "    skin = np.zeros((height,width),np.uint8)\n",
    "    for i in range(0,height):\n",
    "        for j in range(0,width):\n",
    "            B = img[i,j,0]\n",
    "            G = img[i,j,1]\n",
    "            R = img[i,j,2]\n",
    "            if(R-G>=20):\n",
    "                if(G>B):\n",
    "                    sum = R+G+B\n",
    "                    t1 = 100*R-33*sum\n",
    "                    t2 = 100*G-33*sum\n",
    "                    if((t1**2+t2**2)>=4*sum*sum):\n",
    "                        T1 = 10000*G*sum\n",
    "                        lower = -7760*R**2 + 5601*R*sum + 1766*sum**2\n",
    "                        if(T1>lower):\n",
    "                            upper = -13767*R**2 + 10743*R*sum + 1452*sum**2\n",
    "                            if(T1<upper):\n",
    "                                skin[i,j] = 255\n",
    "    cv2.imshow('skin2',skin)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return skin\n",
    "#skin = Quad_poly(img)\n",
    "# 效果垃圾 笑果还行     人脸面部会反光，导致反光区域的RGB值偏高，会被筛选出人脸区域，而人脸轮廓例如脸颊、腮部亮度比较稳定，会被识别为人脸区域\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于HSV颜色空间H，S，V范围筛选法\n",
    "def HSV(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # 把图像转换到HSV色域\n",
    "    (h, s, v) = cv2.split(hsv) # 图像分割, 分别获取h, s, v 通道分量图像\n",
    "    skin = np.zeros(h.shape, np.uint8)  # 根据源图像的大小创建一个全0的矩阵,用于保存图像数据\n",
    "    (height, width) = img.shape[0:2] # 获取源图像数据的长和宽\n",
    "\n",
    "    # 遍历图像, 判断HSV通道的数值, 如果在指定范围中, 则置把新图像的点设为255,否则设为0\n",
    "    for i in  range(0, height):\n",
    "        for j in  range(0, width):\n",
    "            if (h[i][j] >  2) and (h[i][j] <  15) and (s[i][j] >  35) and (s[i][j] <  255) and (v[i][j] >  60) and (v[i][j] <  255):\n",
    "                skin[i][j] =  255\n",
    "            else:\n",
    "                skin[i][j] =  0\n",
    "    cv2.imshow('skin',skin)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    return skin\n",
    "\n",
    "# hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # 把图像转换到HSV色域\n",
    "# cv2.imshow('hsv',hsv)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "#HSV(img)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 双边滤波\n",
    "dst1 = cv2.bilateralFilter(img,15,35,35) # 邻域半径为15 sigma_d为空间高斯函数标准差，sigma_r为灰度值相似性高斯函数标准差\n",
    "#cv2.imshow('dst1',dst1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 磨皮算法 \n",
    "# 通过上述算法获得皮肤区域，遍历双边滤波后的矩阵，将非皮肤区域还原\n",
    "def skin_(dst1,img,skin1):       #dst1 为双边滤波后的矩阵  img 为原图 skin1 为皮肤区域\n",
    "    dst2 = dst1.copy()\n",
    "    for i in range(0,height):   \n",
    "        for j in range(0,width):\n",
    "            if(skin1[i,j] == 0):\n",
    "                dst2[i,j] = img[i,j]\n",
    "\n",
    "    cv2.imshow('dst2',dst2)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
