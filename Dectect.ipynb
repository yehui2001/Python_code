{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "face:1 predictor:0 x:86 y:181\n",
      "face:1 predictor:1 x:87 y:224\n",
      "face:1 predictor:2 x:92 y:266\n",
      "face:1 predictor:3 x:98 y:307\n",
      "face:1 predictor:4 x:110 y:348\n",
      "face:1 predictor:5 x:132 y:384\n",
      "face:1 predictor:6 x:167 y:411\n",
      "face:1 predictor:7 x:205 y:430\n",
      "face:1 predictor:8 x:247 y:438\n",
      "face:1 predictor:9 x:290 y:432\n",
      "face:1 predictor:10 x:329 y:414\n",
      "face:1 predictor:11 x:365 y:389\n",
      "face:1 predictor:12 x:388 y:354\n",
      "face:1 predictor:13 x:402 y:314\n",
      "face:1 predictor:14 x:409 y:272\n",
      "face:1 predictor:15 x:416 y:230\n",
      "face:1 predictor:16 x:419 y:186\n",
      "face:1 predictor:17 x:122 y:157\n",
      "face:1 predictor:18 x:146 y:140\n",
      "face:1 predictor:19 x:176 y:136\n",
      "face:1 predictor:20 x:207 y:141\n",
      "face:1 predictor:21 x:235 y:153\n",
      "face:1 predictor:22 x:279 y:155\n",
      "face:1 predictor:23 x:306 y:144\n",
      "face:1 predictor:24 x:336 y:140\n",
      "face:1 predictor:25 x:365 y:144\n",
      "face:1 predictor:26 x:388 y:161\n",
      "face:1 predictor:27 x:257 y:190\n",
      "face:1 predictor:28 x:256 y:213\n",
      "face:1 predictor:29 x:255 y:237\n",
      "face:1 predictor:30 x:254 y:262\n",
      "face:1 predictor:31 x:227 y:289\n",
      "face:1 predictor:32 x:240 y:293\n",
      "face:1 predictor:33 x:254 y:296\n",
      "face:1 predictor:34 x:268 y:294\n",
      "face:1 predictor:35 x:281 y:291\n",
      "face:1 predictor:36 x:156 y:194\n",
      "face:1 predictor:37 x:174 y:184\n",
      "face:1 predictor:38 x:195 y:185\n",
      "face:1 predictor:39 x:213 y:199\n",
      "face:1 predictor:40 x:194 y:203\n",
      "face:1 predictor:41 x:173 y:202\n",
      "face:1 predictor:42 x:297 y:200\n",
      "face:1 predictor:43 x:316 y:186\n",
      "face:1 predictor:44 x:337 y:187\n",
      "face:1 predictor:45 x:355 y:196\n",
      "face:1 predictor:46 x:337 y:204\n",
      "face:1 predictor:47 x:316 y:205\n",
      "face:1 predictor:48 x:197 y:339\n",
      "face:1 predictor:49 x:222 y:332\n",
      "face:1 predictor:50 x:241 y:325\n",
      "face:1 predictor:51 x:253 y:329\n",
      "face:1 predictor:52 x:265 y:326\n",
      "face:1 predictor:53 x:284 y:335\n",
      "face:1 predictor:54 x:308 y:343\n",
      "face:1 predictor:55 x:283 y:356\n",
      "face:1 predictor:56 x:264 y:360\n",
      "face:1 predictor:57 x:252 y:360\n",
      "face:1 predictor:58 x:239 y:358\n",
      "face:1 predictor:59 x:220 y:353\n",
      "face:1 predictor:60 x:206 y:339\n",
      "face:1 predictor:61 x:241 y:340\n",
      "face:1 predictor:62 x:253 y:342\n",
      "face:1 predictor:63 x:265 y:341\n",
      "face:1 predictor:64 x:299 y:343\n",
      "face:1 predictor:65 x:264 y:343\n",
      "face:1 predictor:66 x:252 y:343\n",
      "face:1 predictor:67 x:240 y:341\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import dlib\n",
    "# 读取图像\n",
    "#srcImg = cv2.imread(\"Images/klst.png\")\n",
    "srcImg=cv2.imread(\"Images/tank.jpg\")\n",
    "\n",
    "img=srcImg.copy()\n",
    "# Step 1：构造人脸检测器（dlib初始化）\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# Step 2：检测人脸框（使用人脸检测器返回检测到的人脸框）\n",
    "faces = detector(img, 1)\n",
    "# Step 3：载入模型（加载预测器）\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "index=0\n",
    "# Step 4：获取每一张脸的关键点（实现检测）\n",
    "for face in faces:\n",
    "    index+=1\n",
    "    # 检测当前人脸的关键点\n",
    "    shape=predictor(img, face)\n",
    "\n",
    "    # 下面对这句代码进行了分解\n",
    "    # landmarks = np.matrix([[p.x, p.y] for p in shape.parts()])\n",
    "    position = np.zeros((68, 2), dtype=int)\n",
    "    # 通过shape.parts()方法遍历关键点\n",
    "    for i, p in enumerate(shape.parts()): \n",
    "        print('face:'+str(index)+' predictor:'+str(i)+' x:'+str(p.x)+' y:'+str(p.y))\n",
    "        # 将关键点的x,y放入一个2列68行的矩阵中,需要知道的是，人脸的每个特征对应的关键点索引是固定的，比如36-42描述的右眼。\n",
    "        landmarks = np.matrix([[p.x, p.y]])\n",
    "        position[i] = (p.x, p.y)\n",
    "        # Step 5：绘制每一张脸的关键点（绘制shape中的每个点）\n",
    "        for idx, point in enumerate(landmarks):\n",
    "            # 当前关键的坐标:[0,1]表示第0行第1个元素\n",
    "            pos = (point[0, 0], point[0, 1])\n",
    "            # 针对当前关键点，绘制一个实心圆\n",
    "            cv2.circle(img, pos, 2, color=(0, 255, 0), thickness=-1)\n",
    "            # 字体\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            # 利用cv2.putText输出1-68,索引序号加1，显示时从1开始。\n",
    "            cv2.putText(img, str(i + 1), pos, font, 0.4, (255, 255, 255), 1, cv2.LINE_AA)\n",
    "            \n",
    "# 绘制结果\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.imshow(\"src\", srcImg)\n",
    "cv2.imwrite(\"woman.png\",img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "眼睛大小为86\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "# 模型初始化\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "\n",
    "# 读取图像\n",
    "srcImg=cv2.imread(\"Images/girl9.jpg\")\n",
    "image=srcImg.copy()\n",
    "# 色彩空间转换彩色(BGR)-->灰度（Gray）\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 获取人脸\n",
    "faces = detector(gray, 3)\n",
    "# 对检测到的rects，逐个遍历\n",
    "\n",
    "for face in faces:\n",
    "    # 针对脸部的关键点进行处理，构成坐标(x,y)形式\n",
    "    shape = np.matrix([[p.x, p.y] for p in predictor(gray, face).parts()])\n",
    "    shape=np.array(shape)\n",
    "    \n",
    "\n",
    "\n",
    "def big_eye_adjust_fast(src, PointX, PointY, Radius,minor_axis,angle,maskImg,feathering_radius, Strength):                                # strength 代表大眼程度 可取负值\n",
    "    processed_image = np.zeros(src.shape, np.uint8)\n",
    "    processed_image = src.copy()\n",
    "    height = src.shape[0]\n",
    "    width = src.shape[1]\n",
    "    PowRadius = Radius * Radius\n",
    " \n",
    "    #maskImg = np.zeros(src.shape[:2], np.uint8)\n",
    "    #cv2.ellipse(maskImg, (PointX, PointY), (Radius,minor_axis) ,angle,0, 360, (255, 255, 255), -1)  #加以改进 采用椭圆区域作为遮罩，用来替换新的坐标值 不太好用\n",
    "    #cv2.circle(maskImg, (PointX, PointY), math.ceil(Radius), (255, 255, 255), -1) # 绘制圆形的mask图像 以radius为半径 颜色为（255,255,255）即白色\n",
    "    cv2.imshow(\"maskImg\", maskImg)\n",
    "    cv2.waitKey(0)\n",
    "    mapX = np.vstack([np.arange(width).astype(np.float32).reshape(1, -1)] * height)             # 创建一个二维数组 用来存放这片区域的横坐标\n",
    "    mapY = np.hstack([np.arange(height).astype(np.float32).reshape(-1, 1)] * width)             # 创建一个二维数组 用来存放这片区域的纵坐标\n",
    " \n",
    "    OffsetX = mapX - PointX\n",
    "    OffsetY = mapY - PointY\n",
    "    dis2 = OffsetX * OffsetX + OffsetY * OffsetY\n",
    " \n",
    "    ScaleFactor = 1 - dis2 / PowRadius                                                          \n",
    "    ScaleFactor = 1 - Strength / 100 * ScaleFactor                                              # 缩放比例因子\n",
    "    UX = OffsetX * ScaleFactor + PointX                                                         # 映射后的Xd = x0 + k*(X1-X0)= x0 + k* OffsetX\n",
    "    UY = OffsetY * ScaleFactor + PointY                                                         \n",
    "    UX[UX < 0] = 0                                                                              \n",
    "    UX[UX >= width] = width - 1                                                                 # 边缘值处理 将映射后处于区域外的坐标值进行边缘处理\n",
    "    UY[UY < 0] = 0\n",
    "    UY[UY >= height] = height - 1\n",
    " \n",
    "    np.copyto(UX, mapX, where=maskImg == 0)                                                     #  替换区域中的值 把mask图像中为0的点 替换为mapX中对应位置的值\n",
    "    np.copyto(UY, mapY, where=maskImg == 0)                                                         \n",
    "\n",
    "    processed_image = cv2.remap(src, UX, UY, interpolation=cv2.INTER_AREA,borderMode=cv2.BORDER_REPLICATE)     # 使用双线性插值法\n",
    " \n",
    "    # 创建羽化遮罩\n",
    "    feathering_mask = np.zeros(src.shape[:2], np.uint8)\n",
    "    #cv2.ellipse(feathering_mask, (PointX, PointY), (Radius+feathering_radius, minor_axis+feathering_radius), angle, 0, 360, (255, 255, 255), -1)\n",
    "    feathering_mask = maskImg\n",
    "    feathering_mask = cv2.GaussianBlur(feathering_mask, (5,5), feathering_radius) / 255\n",
    "    # 应用羽化效果\n",
    "    for i in range(3):  # 对于每个颜色通道\n",
    "        processed_image[:, :, i] = src[:, :, i] * (1 - feathering_mask) + processed_image[:, :, i] * feathering_mask\n",
    "    return processed_image\n",
    "\n",
    "\n",
    "processed_image = srcImg.copy()                                                                 # 通过dlib库中的特征点规定  我们认定36和39为左眼  42和45为右眼（镜像）\n",
    "Radius_left = shape[39][0]-shape[36][0]                             \n",
    "Radius_right = shape[45][0]-shape[42][0]\n",
    "\n",
    "minor_axis_Left = shape[37][0]-shape[41][0]\n",
    "minor_axis_Right = shape[44][0]-shape[47][0]\n",
    "\n",
    "Left_angle = math.degrees(math.atan((shape[39][1]-shape[36][1])/(shape[39][0]-shape[36][0])))\n",
    "Right_angle = math.degrees(math.atan((shape[45][1]-shape[42][1])/(shape[45][0]-shape[42][0])))\n",
    "\n",
    "print(\"眼睛大小为\"+str(max(Radius_left,Radius_right)))\n",
    "minor_axis = int(max(minor_axis_Left,minor_axis_Right)*1.5)\n",
    "\n",
    "height = srcImg.shape[0]\n",
    "width = srcImg.shape[1]\n",
    "\n",
    "# 假设landmarks是一个包含左眼睛特征点坐标的数组\n",
    "landmarks_left = np.array([shape[36],shape[37],shape[38],shape[39],shape[40],shape[41]])\n",
    "landmarks_right = np.array([shape[42],shape[43],shape[44],shape[45],shape[46],shape[47]])\n",
    "# 创建一个与原始图像大小相同的空白掩模\n",
    "maskImg_left = np.zeros((height, width), dtype=np.uint8)\n",
    "maskImg_right = np.zeros((height, width), dtype=np.uint8)\n",
    "# 在掩模上绘制多边形，255是填充颜色\n",
    "cv2.fillPoly(maskImg_left, [landmarks_left], 255)\n",
    "cv2.fillPoly(maskImg_right, [landmarks_right], 255)\n",
    "\n",
    "\n",
    "PointX_left, PointY_left, Radius_left, Strength_left = int((shape[36][0]+shape[39][0])/2), int((shape[37][1]+shape[41][1])/2), Radius_left,10\n",
    "PointX_right, PointY_right, Radius_right, Strength_right = int((shape[42][0]+shape[45][0])/2), int((shape[44][1]+shape[47][1])/2),Radius_right,10\n",
    "\n",
    "#dst = big_eye_adjust_fast(processed_image, PointX_left, PointY_left, Radius_left,minor_axis_Left, Strength_left)[0]\n",
    "processed_image = big_eye_adjust_fast(processed_image, PointX_left, PointY_left, Radius_left,minor_axis,Left_angle,maskImg_left,2,Strength_left)\n",
    "processed_image = big_eye_adjust_fast(processed_image, PointX_right, PointY_right, Radius_right,minor_axis,Right_angle,maskImg_right,2,Strength_right)\n",
    "cv2.imshow(\"img\",srcImg)\n",
    "cv2.imshow(\"big.jpg\", processed_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
